{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBF6Z/2LAj6xmyZovw9eMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "211396f217b149d9bb19c67d888090b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c8ab1d4744a40d8b236c7f51339386b",
              "IPY_MODEL_6ea5086b34484615ac071d3197b1670b",
              "IPY_MODEL_299581a1e28f476ba9db2724a6708063"
            ],
            "layout": "IPY_MODEL_f584e6fcb6ca4811ace04689c8d8d170"
          }
        },
        "9c8ab1d4744a40d8b236c7f51339386b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c67033d43948ecb39f2e792ee69e7c",
            "placeholder": "​",
            "style": "IPY_MODEL_f7474c5fd9a94863aab3d1caed0f1c24",
            "value": "Downloading: 100%"
          }
        },
        "6ea5086b34484615ac071d3197b1670b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71486a381d9d4975b92bbbf53d567cfc",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f424f4c4852042cbb2f614a410172763",
            "value": 995526
          }
        },
        "299581a1e28f476ba9db2724a6708063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f175b89af12d4089abe9f36c7a58ca3b",
            "placeholder": "​",
            "style": "IPY_MODEL_faed7e1805e44925ab8b38e819c0a6b2",
            "value": " 996k/996k [00:00&lt;00:00, 15.4MB/s]"
          }
        },
        "f584e6fcb6ca4811ace04689c8d8d170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c67033d43948ecb39f2e792ee69e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7474c5fd9a94863aab3d1caed0f1c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71486a381d9d4975b92bbbf53d567cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f424f4c4852042cbb2f614a410172763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f175b89af12d4089abe9f36c7a58ca3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faed7e1805e44925ab8b38e819c0a6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c24446e0af3043d2b6f228bb797dd2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12477fe111bd4fb5b91fb04c341cc129",
              "IPY_MODEL_a6b3880a035d44d08119c303232d982a",
              "IPY_MODEL_8e1249de65be4b5bbf2cc389d5ad30c8"
            ],
            "layout": "IPY_MODEL_dfcdd0ffdf01413aadef00d8409e0f41"
          }
        },
        "12477fe111bd4fb5b91fb04c341cc129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601905689cd94203968b67c7d0b03dbe",
            "placeholder": "​",
            "style": "IPY_MODEL_1b0cbb5c0c5347dfa711582d6a641bab",
            "value": "Downloading: 100%"
          }
        },
        "a6b3880a035d44d08119c303232d982a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d7eee94ccd49b2b8318c765b71a8a7",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69daba0d8110488f8cc131a685d9b5c1",
            "value": 29
          }
        },
        "8e1249de65be4b5bbf2cc389d5ad30c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55f064a979994f91a5ee61eebefb55b2",
            "placeholder": "​",
            "style": "IPY_MODEL_988868bc0aa34c7496cd962b556753cd",
            "value": " 29.0/29.0 [00:00&lt;00:00, 966B/s]"
          }
        },
        "dfcdd0ffdf01413aadef00d8409e0f41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601905689cd94203968b67c7d0b03dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b0cbb5c0c5347dfa711582d6a641bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4d7eee94ccd49b2b8318c765b71a8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69daba0d8110488f8cc131a685d9b5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55f064a979994f91a5ee61eebefb55b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988868bc0aa34c7496cd962b556753cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15eb78a926844dfb8ecd61523a444e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_024bedb9c0674d9eb9185293ef809b22",
              "IPY_MODEL_68fb25f7ff9e43ffa4d886f98926ee42",
              "IPY_MODEL_48e86378f5d5478fa2ec418f11d7214c"
            ],
            "layout": "IPY_MODEL_2359ecf2da98418d87b1de02b296b544"
          }
        },
        "024bedb9c0674d9eb9185293ef809b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11839a87991d448990eb832a5869ec44",
            "placeholder": "​",
            "style": "IPY_MODEL_6e41c9c2d7b44df9adf30a54cf5675f8",
            "value": "Downloading: 100%"
          }
        },
        "68fb25f7ff9e43ffa4d886f98926ee42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4e08831357475b838f4727d64aa1f7",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f52ac214fd5c4308a293577c9196c4fd",
            "value": 625
          }
        },
        "48e86378f5d5478fa2ec418f11d7214c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146fcb4c9baa4edea23d2825ea2ed34b",
            "placeholder": "​",
            "style": "IPY_MODEL_8e64c96abc4348f886a5d19f3e74da11",
            "value": " 625/625 [00:00&lt;00:00, 21.3kB/s]"
          }
        },
        "2359ecf2da98418d87b1de02b296b544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11839a87991d448990eb832a5869ec44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e41c9c2d7b44df9adf30a54cf5675f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad4e08831357475b838f4727d64aa1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52ac214fd5c4308a293577c9196c4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "146fcb4c9baa4edea23d2825ea2ed34b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e64c96abc4348f886a5d19f3e74da11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5643d3e3430433782d9a5fa535086bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fe1a0c2063a44388b6929943eaa2bcc",
              "IPY_MODEL_2cff1c721cd14eb9a254660c94650e82",
              "IPY_MODEL_8a4c9c70fffa4a0ea2ecabf719166a9a"
            ],
            "layout": "IPY_MODEL_e44aab92633e4410acd4195a0780a9f8"
          }
        },
        "9fe1a0c2063a44388b6929943eaa2bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f83aabc7f7604dddada5c8591d47299d",
            "placeholder": "​",
            "style": "IPY_MODEL_25b875fcf6a944979004802b484a99bc",
            "value": "Downloading: 100%"
          }
        },
        "2cff1c721cd14eb9a254660c94650e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b432bcc3e1342e4af14451b198d3ce7",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_904bec2668f6410b86efe261d895cf48",
            "value": 714314041
          }
        },
        "8a4c9c70fffa4a0ea2ecabf719166a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d48399019da48f5bdd53bc897d5da17",
            "placeholder": "​",
            "style": "IPY_MODEL_e1937fdb466c4309841f2913d2e3f38d",
            "value": " 714M/714M [00:12&lt;00:00, 54.8MB/s]"
          }
        },
        "e44aab92633e4410acd4195a0780a9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83aabc7f7604dddada5c8591d47299d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b875fcf6a944979004802b484a99bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b432bcc3e1342e4af14451b198d3ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904bec2668f6410b86efe261d895cf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d48399019da48f5bdd53bc897d5da17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1937fdb466c4309841f2913d2e3f38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f530a458bce84e30baf3a1d05d89a711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cf1b84451364edabc85b334196fec34",
              "IPY_MODEL_5989bbfc09e24da9a4c45ec46ecaf5c4",
              "IPY_MODEL_62b5dce8de7e4c3f9be585cd9ce55bf6"
            ],
            "layout": "IPY_MODEL_605894d90e6f403b8b8b8a510f907bc1"
          }
        },
        "5cf1b84451364edabc85b334196fec34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78eb09d5047d40e382a26fd529ee88e3",
            "placeholder": "​",
            "style": "IPY_MODEL_b5746a98b5d14d9cbe2592f329324a23",
            "value": "Downloading: 100%"
          }
        },
        "5989bbfc09e24da9a4c45ec46ecaf5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_443034b8656a4d74ab1d5defe008d02a",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b32bde4dce1b4fd09afb86c1ea8fc56e",
            "value": 615
          }
        },
        "62b5dce8de7e4c3f9be585cd9ce55bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21c7fc2e2b75495d8524e680fe3af3c0",
            "placeholder": "​",
            "style": "IPY_MODEL_a4cbaad7625c481a9b28ef49e46ca624",
            "value": " 615/615 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "605894d90e6f403b8b8b8a510f907bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78eb09d5047d40e382a26fd529ee88e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5746a98b5d14d9cbe2592f329324a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "443034b8656a4d74ab1d5defe008d02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32bde4dce1b4fd09afb86c1ea8fc56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21c7fc2e2b75495d8524e680fe3af3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cbaad7625c481a9b28ef49e46ca624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c7c0d98e3e140c3998f80b2d19030c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59778dce2ddb48d38466046aebf5ca4b",
              "IPY_MODEL_aad1730e72e94166950598de858504eb",
              "IPY_MODEL_25767eeb91624772b91d59aa049bdd5c"
            ],
            "layout": "IPY_MODEL_5579b9b73a694c798df54cdd9410ab68"
          }
        },
        "59778dce2ddb48d38466046aebf5ca4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5247b467b94c69b0c1b131f8a3a959",
            "placeholder": "​",
            "style": "IPY_MODEL_62b4551487f9439fa47222b5a2c9040b",
            "value": "Downloading: 100%"
          }
        },
        "aad1730e72e94166950598de858504eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e100b2487f7e44e19e17b0812aaf6a0e",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d209f8be403a4246833039e664c1780c",
            "value": 1115590446
          }
        },
        "25767eeb91624772b91d59aa049bdd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c99c615a3114db5863c66008dfbd4f8",
            "placeholder": "​",
            "style": "IPY_MODEL_d488761492a24f3ba3fa43e43a2c29d6",
            "value": " 1.12G/1.12G [00:22&lt;00:00, 57.2MB/s]"
          }
        },
        "5579b9b73a694c798df54cdd9410ab68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5247b467b94c69b0c1b131f8a3a959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b4551487f9439fa47222b5a2c9040b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e100b2487f7e44e19e17b0812aaf6a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d209f8be403a4246833039e664c1780c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c99c615a3114db5863c66008dfbd4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d488761492a24f3ba3fa43e43a2c29d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7c2d54e7574a30a5c0fafd84391e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49690c21ee09412a9b50827139781596",
              "IPY_MODEL_272d850734f645eba0f4f081d9dc55f2",
              "IPY_MODEL_c7044c9995fe449ab8791f66600d99c1"
            ],
            "layout": "IPY_MODEL_663f08d2652a4869b395e5695031d0d9"
          }
        },
        "49690c21ee09412a9b50827139781596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc1a74811ee4f6894ea43b7da18d460",
            "placeholder": "​",
            "style": "IPY_MODEL_828f1d582e5c49e5a548f14dce266a26",
            "value": "Downloading: 100%"
          }
        },
        "272d850734f645eba0f4f081d9dc55f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d6585759be4ef285fc77af74b80435",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f54393ceee840e2b5ed9d51e3ccf2a0",
            "value": 714314041
          }
        },
        "c7044c9995fe449ab8791f66600d99c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263f0c27f3a74106b034e22dd82ecd3d",
            "placeholder": "​",
            "style": "IPY_MODEL_ff50775f12034c45a246612514a7cf7f",
            "value": " 714M/714M [00:11&lt;00:00, 65.1MB/s]"
          }
        },
        "663f08d2652a4869b395e5695031d0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc1a74811ee4f6894ea43b7da18d460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828f1d582e5c49e5a548f14dce266a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4d6585759be4ef285fc77af74b80435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f54393ceee840e2b5ed9d51e3ccf2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "263f0c27f3a74106b034e22dd82ecd3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff50775f12034c45a246612514a7cf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebf4564248bb43d795d6f99d61b100fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2935003078a48e298a8b7efcbef7010",
              "IPY_MODEL_eff64216f4a64752916832d01424152b",
              "IPY_MODEL_29da9ba5c2ee4b9b95e6a3ba79604adf"
            ],
            "layout": "IPY_MODEL_7fbfb47306f14a378f2fce181e6018c1"
          }
        },
        "e2935003078a48e298a8b7efcbef7010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc029de199644040b058fec65052a676",
            "placeholder": "​",
            "style": "IPY_MODEL_57b51100f3f24bb1be1d81656b7db8fe",
            "value": "Downloading: 100%"
          }
        },
        "eff64216f4a64752916832d01424152b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cd97a8a5fbe40d48f15386e266603fc",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2197d15eecc34780b37600a2645ccdf1",
            "value": 615
          }
        },
        "29da9ba5c2ee4b9b95e6a3ba79604adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4ffc7afe3954b7fa0508b3c18053742",
            "placeholder": "​",
            "style": "IPY_MODEL_755389b9cbb34b59867774472e5858a4",
            "value": " 615/615 [00:00&lt;00:00, 15.2kB/s]"
          }
        },
        "7fbfb47306f14a378f2fce181e6018c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc029de199644040b058fec65052a676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b51100f3f24bb1be1d81656b7db8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cd97a8a5fbe40d48f15386e266603fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2197d15eecc34780b37600a2645ccdf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4ffc7afe3954b7fa0508b3c18053742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755389b9cbb34b59867774472e5858a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a415bea64d4a5db9f84585e169dcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3436c889ce144e95ad3c353bf9d20c2a",
              "IPY_MODEL_ea76dfc4a694468a82f5a49131b08a34",
              "IPY_MODEL_04acef6ec3d549cb98451591e5758fec"
            ],
            "layout": "IPY_MODEL_bf829f583a1840ff82ae9103f9f9c086"
          }
        },
        "3436c889ce144e95ad3c353bf9d20c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_780cf6e819b94e0893c0ae30e1ea447e",
            "placeholder": "​",
            "style": "IPY_MODEL_5db3dfcd0f88499996d6dca068518b4b",
            "value": "Downloading: 100%"
          }
        },
        "ea76dfc4a694468a82f5a49131b08a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7786cb8380b54094a96b684261a1c182",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cdf9a93488e49db80b44a494f12fe33",
            "value": 5069051
          }
        },
        "04acef6ec3d549cb98451591e5758fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8767b44f4e7e45d7b27f6522f5c8b139",
            "placeholder": "​",
            "style": "IPY_MODEL_fcc9d09f17034790ad4c616ea75ecf43",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "bf829f583a1840ff82ae9103f9f9c086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780cf6e819b94e0893c0ae30e1ea447e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5db3dfcd0f88499996d6dca068518b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7786cb8380b54094a96b684261a1c182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdf9a93488e49db80b44a494f12fe33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8767b44f4e7e45d7b27f6522f5c8b139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc9d09f17034790ad4c616ea75ecf43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4185ac4e26d45d4b9559ce802a56ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c852e31ed9b4ba9a1c9f0d265af7992",
              "IPY_MODEL_3a963caabb7c4c538ccccfca379e3dcf",
              "IPY_MODEL_c0590832b7b145bbb5c444e078186040"
            ],
            "layout": "IPY_MODEL_98105be7070b46348e7d2a133665f2af"
          }
        },
        "4c852e31ed9b4ba9a1c9f0d265af7992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3421fffa8cd47dda78c7c51968af956",
            "placeholder": "​",
            "style": "IPY_MODEL_166b736bf3a44d3baeacf4f49aed501c",
            "value": "Downloading: 100%"
          }
        },
        "3a963caabb7c4c538ccccfca379e3dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be24b2844f3a43fbaa7783030e5649b7",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92f9e5f77b1e4e538656096e551b93d4",
            "value": 9096718
          }
        },
        "c0590832b7b145bbb5c444e078186040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4d41623814487f8a75f54cade35f33",
            "placeholder": "​",
            "style": "IPY_MODEL_4a2e835c9b724d57adda9f8846cfb2e0",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 15.5MB/s]"
          }
        },
        "98105be7070b46348e7d2a133665f2af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3421fffa8cd47dda78c7c51968af956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "166b736bf3a44d3baeacf4f49aed501c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be24b2844f3a43fbaa7783030e5649b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f9e5f77b1e4e538656096e551b93d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da4d41623814487f8a75f54cade35f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a2e835c9b724d57adda9f8846cfb2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0abcc5c11c640bb8f7e9a2142ecf2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12554d76e0b140d0acc1efa38f0aa0a7",
              "IPY_MODEL_3d1d435d8b4147fa9f26a767aecb60cd",
              "IPY_MODEL_82dde2c3b9db47fb9d4b722839cfb811"
            ],
            "layout": "IPY_MODEL_9cc7fea2e6c844479140d848afcf2331"
          }
        },
        "12554d76e0b140d0acc1efa38f0aa0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b680c64dc6450e81c13ce427f44199",
            "placeholder": "​",
            "style": "IPY_MODEL_e00e1740f452458cabbf2c42775c549f",
            "value": "Downloading: 100%"
          }
        },
        "3d1d435d8b4147fa9f26a767aecb60cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8355fb3df24e46db8968eaa3dc3a909c",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e73606ad1b242b3a96f362d8872df31",
            "value": 1115590446
          }
        },
        "82dde2c3b9db47fb9d4b722839cfb811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_985f7c69e17045e6b1b0c6e73c4687dc",
            "placeholder": "​",
            "style": "IPY_MODEL_27de64b7013443d9999beadf7d6d2235",
            "value": " 1.12G/1.12G [00:18&lt;00:00, 60.0MB/s]"
          }
        },
        "9cc7fea2e6c844479140d848afcf2331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b680c64dc6450e81c13ce427f44199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00e1740f452458cabbf2c42775c549f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8355fb3df24e46db8968eaa3dc3a909c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e73606ad1b242b3a96f362d8872df31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "985f7c69e17045e6b1b0c6e73c4687dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27de64b7013443d9999beadf7d6d2235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namkibeom/Korean-ABSA/blob/main/Korean_ABSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vItpu7dptgvI",
        "outputId": "a59df2dd-e562-4dd5-f2c8-01c088095737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LorenzoAgnolucci/BERT_for_ABSA.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zR7zabltgyT",
        "outputId": "8405edd5-e6dd-4260-edc3-cdc63d9cf288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BERT_for_ABSA'...\n",
            "remote: Enumerating objects: 284, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 284 (delta 5), reused 3 (delta 3), pack-reused 277\u001b[K\n",
            "Receiving objects: 100% (284/284), 10.14 MiB | 6.46 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a dataset and a task { run: \"auto\", display-mode: \"form\" }\n",
        "base_dir = \"/gdrive/MyDrive/Machine_Learning\" #@param {type:\"string\"}\n",
        "dataset_type = \"semeval2014\" #@param [\"sentihood\", \"semeval2014\"]\n",
        "task = \"NLI_M_Kor\" #@param [\"QA_M\", \"NLI_M\", \"QA_B\", \"NLI_B\", \"NLI_M_Kor\"]"
      ],
      "metadata": {
        "id": "QEUt127jtg17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    id2label = {0: \"None\", 1: \"Positive\", 2: \"Negative\"}\n",
        "    label2id = {\"None\": 0, \"Positive\": 1, \"Negative\": 2}\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    id2label = {0: \"긍정\", 1: \"중립\", 2: \"부정\", 3: \"대립\", 4: \"없음\"}\n",
        "    label2id = {\"긍정\": 0, \"중립\" : 1, \"부정\" : 2, \"대립\": 3, \"없음\": 4}\n",
        "\n",
        "if task.endswith(\"B\"):\n",
        "    num_classes = 2\n",
        "else:\n",
        "    if dataset_type == \"sentihood\":\n",
        "        num_classes = 3\n",
        "    elif dataset_type == \"semeval2014\":\n",
        "        num_classes = 5\n",
        "\n",
        "\n",
        "def get_dataset(path):\n",
        "    original_sentences = []\n",
        "    auxiliary_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(path, header=0, error_bad_lines= False).values.tolist()\n",
        "    for row in data:\n",
        "        original_sentences.append(row[1])\n",
        "        auxiliary_sentences.append(row[2])\n",
        "        labels.append(row[3])\n",
        "    return original_sentences, auxiliary_sentences, labels\n",
        "\n",
        "\n",
        "\n",
        "train_original_sentences, train_auxiliary_sentences, train_labels = get_dataset(f\"/content/train_NLI_M_Kor.csv\")\n",
        "#if dataset_type == \"sentihood\":\n",
        "    #val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/dev_{task}.csv\")\n",
        "#elif dataset_type == \"semeval2014\":\n",
        "val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"/content/test_NLI_M_Kor.csv\")\n",
        "test_original_sentences, test_auxiliary_sentences, test_labels = get_dataset(f\"/content/test_NLI_M_Kor.csv\")\n",
        "\n",
        "test2_original_sentences, test2_auxiliary_sentences, test2_labels = get_dataset(f\"/content/kakao_NLI_M_Kor.csv\")"
      ],
      "metadata": {
        "id": "0PCScqHRtg5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "3c67be55-698f-4bd3-945e-154184c1b6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9b6fb58b9acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrain_original_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auxiliary_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/train_NLI_M_Kor.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#if dataset_type == \"sentihood\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/dev_{task}.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-9b6fb58b9acf>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mauxiliary_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moriginal_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train_NLI_M_Kor.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KR3\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    id2label = {0: \"None\", 1: \"Positive\", 2: \"Negative\"}\n",
        "    label2id = {\"None\": 0, \"Positive\": 1, \"Negative\": 2}\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    id2label = {0: \"긍정\", 1: \"중립\", 2: \"부정\", 3: \"대립\", 4: \"없음\"}\n",
        "    label2id = {\"긍정\": 0, \"중립\" : 1, \"부정\" : 2, \"대립\": 3, \"없음\": 4}\n",
        "\n",
        "if task.endswith(\"B\"):\n",
        "    num_classes = 2\n",
        "else:\n",
        "    if dataset_type == \"sentihood\":\n",
        "        num_classes = 3\n",
        "    elif dataset_type == \"semeval2014\":\n",
        "        num_classes = 5\n",
        "\n",
        "\n",
        "def get_dataset(path):\n",
        "    original_sentences = []\n",
        "    auxiliary_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(path, header=0, error_bad_lines= False).values.tolist()\n",
        "    for row in data:\n",
        "        original_sentences.append(row[1])\n",
        "        auxiliary_sentences.append(row[2])\n",
        "        labels.append(row[3])\n",
        "    return original_sentences, auxiliary_sentences, labels\n",
        "\n",
        "\n",
        "\n",
        "train_original_sentences, train_auxiliary_sentences, train_labels = get_dataset(f\"/content/KR3_pair_train.csv\")\n",
        "#if dataset_type == \"sentihood\":\n",
        "    #val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/dev_{task}.csv\")\n",
        "#elif dataset_type == \"semeval2014\":\n",
        "val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"/content/KR3_pair_test.csv\")\n",
        "test_original_sentences, test_auxiliary_sentences, test_labels = get_dataset(f\"/content/KR3_pair_test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDKDqDrL7jNd",
        "outputId": "3201d6e6-da5b-4aec-b313-d9a570ff0fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kakao\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    id2label = {0: \"None\", 1: \"Positive\", 2: \"Negative\"}\n",
        "    label2id = {\"None\": 0, \"Positive\": 1, \"Negative\": 2}\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    id2label = {0: \"긍정\", 1: \"중립\", 2: \"부정\", 3: \"대립\", 4: \"없음\"}\n",
        "    label2id = {\"긍정\": 0, \"중립\" : 1, \"부정\" : 2, \"대립\": 3, \"없음\": 4}\n",
        "\n",
        "if task.endswith(\"B\"):\n",
        "    num_classes = 2\n",
        "else:\n",
        "    if dataset_type == \"sentihood\":\n",
        "        num_classes = 3\n",
        "    elif dataset_type == \"semeval2014\":\n",
        "        num_classes = 5\n",
        "\n",
        "\n",
        "def get_dataset(path):\n",
        "    original_sentences = []\n",
        "    auxiliary_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(path, header=0, error_bad_lines= False).values.tolist()\n",
        "    for row in data:\n",
        "        original_sentences.append(row[1])\n",
        "        auxiliary_sentences.append(row[2])\n",
        "        labels.append(row[3])\n",
        "    return original_sentences, auxiliary_sentences, labels\n",
        "\n",
        "\n",
        "\n",
        "train_original_sentences, train_auxiliary_sentences, train_labels = get_dataset(f\"/content/train_kakao_NLI_M_Kor.csv\")\n",
        "#if dataset_type == \"sentihood\":\n",
        "    #val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-pair/dev_{task}.csv\")\n",
        "#elif dataset_type == \"semeval2014\":\n",
        "val_original_sentences, val_auxiliary_sentences, val_labels = get_dataset(f\"/content/test_kakao_NLI_M_Kor.csv\")\n",
        "test_original_sentences, test_auxiliary_sentences, test_labels = get_dataset(f\"/content/test_kakao_NLI_M_Kor.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7GbOo1LMKcK",
        "outputId": "52548678-4264-41f0-ae23-9539f9a9d505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xlm-roberta 주요 라이브러리 설치\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "_sPrmENjZIh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d63fba3-e189-449a-8f1c-545c8b79c0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595728 sha256=c2ca0d4e562b98c548a08090a58d29923a8e13a300be63831413fddb9a8d594c\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 14.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO5qV92bloXQ",
        "outputId": "706c10b1-e93e-44e6-8bf7-bec53eae1cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT용\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "train_encodings = tokenizer(train_original_sentences, train_auxiliary_sentences, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_original_sentences, val_auxiliary_sentences, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_original_sentences, test_auxiliary_sentences, truncation=True, padding=True)\n",
        "\n",
        "#test2_encodings = tokenizer(test2_original_sentences, test2_auxiliary_sentences, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "TorhmZ7d3Ymj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a5c479-0fcb-4df0-eb03-b9809a621241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CBK2MbQnsC5",
        "outputId": "0d858b1b-baec-49dc-d610-52df8fe48b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Xlm-roberta용\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "train_encodings = tokenizer(train_original_sentences, train_auxiliary_sentences, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_original_sentences, val_auxiliary_sentences, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_original_sentences, test_auxiliary_sentences, truncation=True, padding=True)\n",
        "\n",
        "#test2_encodings = tokenizer(test2_original_sentences, test2_auxiliary_sentences, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "OFQ9oymxtg9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ebf4564248bb43d795d6f99d61b100fa",
            "e2935003078a48e298a8b7efcbef7010",
            "eff64216f4a64752916832d01424152b",
            "29da9ba5c2ee4b9b95e6a3ba79604adf",
            "7fbfb47306f14a378f2fce181e6018c1",
            "cc029de199644040b058fec65052a676",
            "57b51100f3f24bb1be1d81656b7db8fe",
            "3cd97a8a5fbe40d48f15386e266603fc",
            "2197d15eecc34780b37600a2645ccdf1",
            "d4ffc7afe3954b7fa0508b3c18053742",
            "755389b9cbb34b59867774472e5858a4",
            "52a415bea64d4a5db9f84585e169dcfc",
            "3436c889ce144e95ad3c353bf9d20c2a",
            "ea76dfc4a694468a82f5a49131b08a34",
            "04acef6ec3d549cb98451591e5758fec",
            "bf829f583a1840ff82ae9103f9f9c086",
            "780cf6e819b94e0893c0ae30e1ea447e",
            "5db3dfcd0f88499996d6dca068518b4b",
            "7786cb8380b54094a96b684261a1c182",
            "8cdf9a93488e49db80b44a494f12fe33",
            "8767b44f4e7e45d7b27f6522f5c8b139",
            "fcc9d09f17034790ad4c616ea75ecf43",
            "f4185ac4e26d45d4b9559ce802a56ba1",
            "4c852e31ed9b4ba9a1c9f0d265af7992",
            "3a963caabb7c4c538ccccfca379e3dcf",
            "c0590832b7b145bbb5c444e078186040",
            "98105be7070b46348e7d2a133665f2af",
            "c3421fffa8cd47dda78c7c51968af956",
            "166b736bf3a44d3baeacf4f49aed501c",
            "be24b2844f3a43fbaa7783030e5649b7",
            "92f9e5f77b1e4e538656096e551b93d4",
            "da4d41623814487f8a75f54cade35f33",
            "4a2e835c9b724d57adda9f8846cfb2e0"
          ]
        },
        "outputId": "856dddb2-c875-4222-ea92-d395f086ee4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebf4564248bb43d795d6f99d61b100fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52a415bea64d4a5db9f84585e169dcfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4185ac4e26d45d4b9559ce802a56ba1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install 'git+https://github.com/SKTBrain/KOBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKOaEwK9p-d0",
        "outputId": "196d4a88-b6e2-45c0-b951-b9648710e1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KOBERT.git to /tmp/pip-install-1j0_82tc/kobert-tokenizer_8655a3cc92a04970b58421340fc78301\n",
            "  Running command git clone -q https://github.com/SKTBrain/KOBERT.git /tmp/pip-install-1j0_82tc/kobert-tokenizer_8655a3cc92a04970b58421340fc78301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install torch\n",
        " import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxK8Ew1ushKt",
        "outputId": "e457235c-39c3-4a61-fdf3-08d9149043bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kobert\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "\n",
        "#train_encodings = tokenizer(train_original_sentences, train_auxiliary_sentences, truncation=True, padding=True)\n",
        "#val_encodings = tokenizer(val_original_sentences, val_auxiliary_sentences, truncation=True, padding=True)\n",
        "#test_encodings = tokenizer(test_original_sentences, test_auxiliary_sentences, truncation=True, padding=True)\n",
        "\n",
        "#test2_encodings = tokenizer(test2_original_sentences, test2_auxiliary_sentences, truncation=True, padding=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "VIctDffRpTzq",
        "outputId": "54d958fb-f9ad-4926-ee88-0dc285cbdcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6ba327098807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#kobert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkobert_tokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKoBERTTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKoBERTTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skt/kobert-base-v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#train_encodings = tokenizer(train_original_sentences, train_auxiliary_sentences, truncation=True, padding=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class ABSA_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ABSA_Dataset(train_encodings, train_labels)\n",
        "val_dataset = ABSA_Dataset(val_encodings, val_labels)\n",
        "test_dataset = ABSA_Dataset(test_encodings, test_labels)\n",
        "\n",
        "#test2_dataset = ABSA_Dataset(test2_encodings, test2_labels)"
      ],
      "metadata": {
        "id": "a1iuH8GlthCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP39M9HhIWNC",
        "outputId": "07ea1b48-3de5-4462-cf75-fee467a35d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluation\n",
            "  Downloading evaluation-0.0.2.tar.gz (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from evaluation) (1.21.6)\n",
            "Collecting glog\n",
            "  Downloading glog-0.3.1-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from glog->evaluation) (1.15.0)\n",
            "Collecting python-gflags>=3.1\n",
            "  Downloading python-gflags-3.1.2.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 863 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: evaluation, python-gflags\n",
            "  Building wheel for evaluation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for evaluation: filename=evaluation-0.0.2-py3-none-any.whl size=2479 sha256=72152e9b9e23fcb11cdda65e34c7d25eaf02877255795f9dbfc6aa0e517dceb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/75/b8/63929bfb42b59346c83a70f51ef709888e344cb34172930ef2\n",
            "  Building wheel for python-gflags (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-gflags: filename=python_gflags-3.1.2-py3-none-any.whl size=57386 sha256=791c301a073e5167caab057798513c9276fbd6690fe2d6766753f58ff7f0af13\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/27/8a/e46bf628958f821f7d2092f276f5a81e184bcf1a1ccdeecd95\n",
            "Successfully built evaluation python-gflags\n",
            "Installing collected packages: python-gflags, glog, evaluation\n",
            "Successfully installed evaluation-0.0.2 glog-0.3.1 python-gflags-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if base_dir not in sys.path:\n",
        "    sys.path.insert(0, f'{base_dir}/')\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import evaluation\n",
        "\n",
        "\n",
        "def get_test_labels(data_dir, dataset_type):\n",
        "    original_sentences = []\n",
        "    auxiliary_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(f\"{data_dir}/{dataset_type}/BERT-pair/KR3_pair_test.csv\", header=0).values.tolist()\n",
        "    for row in data:\n",
        "        labels.append(row[3])\n",
        "    return labels\n",
        "\n",
        "\n",
        "def get_predictions(data, task, dataset_type):\n",
        "    predicted_labels = []\n",
        "    scores = []\n",
        "    if task.endswith(\"B\"):\n",
        "        if dataset_type == \"sentihood\":\n",
        "            if task.endswith(\"B\"):\n",
        "                count_aspect_rows = 0\n",
        "                current_aspect_scores = []\n",
        "                for row in data:\n",
        "                    current_aspect_scores.append(row[2])\n",
        "                    count_aspect_rows += 1\n",
        "                    if count_aspect_rows % 3 == 0:\n",
        "                        sum_current_aspect_scores = np.sum(current_aspect_scores)\n",
        "                        current_aspect_scores = [score / sum_current_aspect_scores for score in current_aspect_scores]\n",
        "                        scores.append(current_aspect_scores)\n",
        "                        predicted_labels.append(np.argmax(current_aspect_scores))\n",
        "                        current_aspect_scores = []\n",
        "        elif dataset_type == \"semeval2014\":\n",
        "            if task.endswith(\"B\"):\n",
        "                count_aspect_rows = 0\n",
        "                current_aspect_scores = []\n",
        "                for row in data:\n",
        "                    current_aspect_scores.append(row[2])\n",
        "                    count_aspect_rows += 1\n",
        "                    if count_aspect_rows % 5 == 0:\n",
        "                        sum_current_aspect_scores = np.sum(current_aspect_scores)\n",
        "                        current_aspect_scores = [score / sum_current_aspect_scores for score in current_aspect_scores]\n",
        "                        scores.append(current_aspect_scores)\n",
        "                        predicted_labels.append(np.argmax(current_aspect_scores))\n",
        "                        current_aspect_scores = []\n",
        "    return predicted_labels, scores\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    def compute_metrics(predictions):\n",
        "        scores = [softmax(prediction) for prediction in predictions[0]]\n",
        "        predicted_labels = [np.argmax(x) for x in scores]\n",
        "        if task.endswith(\"B\"):\n",
        "            data = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "            predicted_labels, scores = get_predictions(data, task, dataset_type)\n",
        "        test_labels = get_test_labels(f\"{base_dir}/data\", dataset_type)\n",
        "        metrics = {}\n",
        "        metrics[\"strict_acc\"] = evaluation.compute_sentihood_aspect_strict_accuracy(test_labels, predicted_labels)\n",
        "        metrics[\"F1\"] = evaluation.compute_sentihood_aspect_macro_F1(test_labels, predicted_labels)\n",
        "        metrics[\"aspect_AUC\"] = evaluation.compute_sentihood_aspect_macro_AUC(test_labels, scores)\n",
        "        sentiment_macro_AUC, sentiment_accuracy = evaluation.compute_sentihood_sentiment_classification_metrics(test_labels, scores)\n",
        "        metrics[\"sentiment_acc\"] = sentiment_accuracy\n",
        "        metrics[\"sentiment_AUC\"] = sentiment_macro_AUC\n",
        "        return metrics\n",
        "\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    def compute_metrics(predictions):\n",
        "        scores = [softmax(prediction) for prediction in predictions[0]]\n",
        "        predicted_labels = [np.argmax(x) for x in scores]\n",
        "        if task.endswith(\"B\"):\n",
        "            data = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "            predicted_labels, scores = get_predictions(data, task, dataset_type)\n",
        "        test_labels = get_test_labels(f\"{base_dir}/data\", dataset_type)\n",
        "        metrics = {}\n",
        "        p, r, f1 = evaluation.compute_semeval_PRF(test_labels, predicted_labels)\n",
        "        metrics[\"P\"] = p\n",
        "        metrics[\"R\"] = r\n",
        "        metrics[\"F1\"] = f1\n",
        "        metrics[\"4-way\"] = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 4)\n",
        "        metrics[\"3-way\"] = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 3)\n",
        "        metrics[\"binary\"] = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 2)\n",
        "        return metrics"
      ],
      "metadata": {
        "id": "hoM9bwNW1Cle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluation\n",
        "%run evaluation.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9enaz3w0NPJq",
        "outputId": "c583b011-306d-4d16-dbe8-ca90e2998772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:File `'evaluation.py'` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertConfig\n",
        "from transformers import logging\n",
        "logging.set_verbosity_debug()\n",
        "\n",
        "\n",
        "epochs = 2\n",
        "batch_size = 3\n",
        "num_steps = len(train_dataset) * epochs // batch_size\n",
        "warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = f'{base_dir}/models/{dataset_type}/BERT-pair/{task}/',          \n",
        "    num_train_epochs = epochs,              \n",
        "    per_device_train_batch_size = batch_size,  \n",
        "    per_device_eval_batch_size = batch_size,   \n",
        "    warmup_steps = warmup_steps,   \n",
        "    weight_decay = 0.01,               \n",
        "    logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-pair/{task}/',            \n",
        "    logging_steps = 10,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    learning_rate = 2e-5,\n",
        "    save_steps = save_steps\n",
        ")\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "    'bert-base-multilingual-cased',\n",
        "    architectures = ['BertForSequenceClassification'],\n",
        "    hidden_size = 768,\n",
        "    num_hidden_layers = 12,\n",
        "    num_attention_heads = 12,\n",
        "    hidden_dropout_prob = 0.1,\n",
        "    num_labels = num_classes\n",
        ")    \n",
        "\n",
        "#load_finetuned_model = True\n",
        "#if not load_finetuned_model:\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', ignore_mismatched_sizes=True, config=config)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                  \n",
        "    train_dataset=train_dataset,         \n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics             \n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step\")\n",
        "\n",
        "#else:\n",
        "#    model = BertForSequenceClassification.from_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step\")\n",
        "#\n",
        "#    trainer = Trainer(\n",
        "#        model=model,                         \n",
        "#        args=training_args,                  \n",
        "#        train_dataset=train_dataset,         \n",
        "#        eval_dataset=val_dataset,\n",
        "#        compute_metrics=compute_metrics             \n",
        "#    )"
      ],
      "metadata": {
        "id": "Kgqb1p7wQeLb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ff7c2d54e7574a30a5c0fafd84391e3c",
            "49690c21ee09412a9b50827139781596",
            "272d850734f645eba0f4f081d9dc55f2",
            "c7044c9995fe449ab8791f66600d99c1",
            "663f08d2652a4869b395e5695031d0d9",
            "0dc1a74811ee4f6894ea43b7da18d460",
            "828f1d582e5c49e5a548f14dce266a26",
            "e4d6585759be4ef285fc77af74b80435",
            "7f54393ceee840e2b5ed9d51e3ccf2a0",
            "263f0c27f3a74106b034e22dd82ecd3d",
            "ff50775f12034c45a246612514a7cf7f"
          ]
        },
        "outputId": "8566247d-ffb7-46dc-a292-cf0dc6b79294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff7c2d54e7574a30a5c0fafd84391e3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15225\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 3\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10150' max='10150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10150/10150 1:08:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F1</th>\n",
              "      <th>4-way</th>\n",
              "      <th>3-way</th>\n",
              "      <th>Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.275800</td>\n",
              "      <td>0.543053</td>\n",
              "      <td>0.910088</td>\n",
              "      <td>0.813725</td>\n",
              "      <td>0.859213</td>\n",
              "      <td>0.821569</td>\n",
              "      <td>0.822375</td>\n",
              "      <td>0.842211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.214600</td>\n",
              "      <td>0.424672</td>\n",
              "      <td>0.925566</td>\n",
              "      <td>0.841176</td>\n",
              "      <td>0.881356</td>\n",
              "      <td>0.864706</td>\n",
              "      <td>0.865554</td>\n",
              "      <td>0.884422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-5075\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-5075/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-5075/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4005\n",
            "  Batch size = 3\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-10150\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-10150/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-10150/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4005\n",
            "  Batch size = 3\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Xlm-RoBERTa-base\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig, Trainer, TrainingArguments\n",
        "from transformers import logging\n",
        "logging.set_verbosity_debug()\n",
        "\n",
        "\n",
        "epochs = 2\n",
        "batch_size = 3\n",
        "num_steps = len(train_dataset) * epochs // batch_size\n",
        "warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = f'{base_dir}/models/{dataset_type}/BERT-pair/{task}/',          \n",
        "    num_train_epochs = epochs,              \n",
        "    per_device_train_batch_size = batch_size,  \n",
        "    per_device_eval_batch_size = batch_size,   \n",
        "    warmup_steps = warmup_steps,   \n",
        "    weight_decay = 0.01,               \n",
        "    logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-pair/{task}/',            \n",
        "    logging_steps = 10,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    learning_rate = 2e-5,\n",
        "    save_steps = save_steps\n",
        ")\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    'xlm-roberta-base',\n",
        "    architectures = ['AutoModelForSequenceClassification'],\n",
        "    hidden_size = 768,\n",
        "    num_hidden_layers = 12,\n",
        "    num_attention_heads = 12,\n",
        "    hidden_dropout_prob = 0.1,\n",
        "    num_labels = num_classes\n",
        ")    \n",
        "\n",
        "#load_finetuned_model = True\n",
        "#if not load_finetuned_model:\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", ignore_mismatched_sizes=True, config=config)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                  \n",
        "    train_dataset=train_dataset,         \n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics             \n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step3\")\n",
        "\n",
        "\n",
        "#else:\n",
        "#    model = BertForSequenceClassification.from_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step\")\n",
        "#\n",
        "#    trainer = Trainer(\n",
        "#        model=model,                         \n",
        "#        args=training_args,                  \n",
        "#        train_dataset=train_dataset,         \n",
        "#        eval_dataset=val_dataset,\n",
        "#        compute_metrics=compute_metrics             \n",
        "#    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c0abcc5c11c640bb8f7e9a2142ecf2ac",
            "12554d76e0b140d0acc1efa38f0aa0a7",
            "3d1d435d8b4147fa9f26a767aecb60cd",
            "82dde2c3b9db47fb9d4b722839cfb811",
            "9cc7fea2e6c844479140d848afcf2331",
            "89b680c64dc6450e81c13ce427f44199",
            "e00e1740f452458cabbf2c42775c549f",
            "8355fb3df24e46db8968eaa3dc3a909c",
            "3e73606ad1b242b3a96f362d8872df31",
            "985f7c69e17045e6b1b0c6e73c4687dc",
            "27de64b7013443d9999beadf7d6d2235"
          ]
        },
        "id": "86zc14yv1Cpp",
        "outputId": "57167a37-720c-483a-88f2-e61d4fb59482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"AutoModelForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0abcc5c11c640bb8f7e9a2142ecf2ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15225\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 3\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10150' max='10150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10150/10150 1:11:33, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F1</th>\n",
              "      <th>4-way</th>\n",
              "      <th>3-way</th>\n",
              "      <th>Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.201700</td>\n",
              "      <td>0.498390</td>\n",
              "      <td>0.930617</td>\n",
              "      <td>0.828431</td>\n",
              "      <td>0.876556</td>\n",
              "      <td>0.869608</td>\n",
              "      <td>0.870461</td>\n",
              "      <td>0.891457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.325700</td>\n",
              "      <td>0.383543</td>\n",
              "      <td>0.924195</td>\n",
              "      <td>0.872549</td>\n",
              "      <td>0.897630</td>\n",
              "      <td>0.906863</td>\n",
              "      <td>0.907753</td>\n",
              "      <td>0.930653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-5075\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-5075/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-5075/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4005\n",
            "  Batch size = 3\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-10150\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-10150/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/checkpoint-10150/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4005\n",
            "  Batch size = 3\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step3/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step3/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoConfig, Trainer, TrainingArguments\n",
        "from transformers import logging\n",
        "logging.set_verbosity_debug() \n",
        "\n",
        "epochs = 2\n",
        "batch_size = 3\n",
        "num_steps = len(train_dataset) * epochs // batch_size\n",
        "warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = f'{base_dir}/models/{dataset_type}/BERT-pair/{task}/',          \n",
        "    num_train_epochs = epochs,              \n",
        "    per_device_train_batch_size = batch_size,  \n",
        "    per_device_eval_batch_size = batch_size,   \n",
        "    warmup_steps = warmup_steps,   \n",
        "    weight_decay = 0.01,               \n",
        "    logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-pair/{task}/',            \n",
        "    logging_steps = 10,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    learning_rate = 2e-5,\n",
        "    save_steps = save_steps\n",
        ")\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    'xlm-roberta-base',\n",
        "    architectures = ['AutoModelForSequenceClassification'],\n",
        "    hidden_size = 768,\n",
        "    num_hidden_layers = 12,\n",
        "    num_attention_heads = 12,\n",
        "    hidden_dropout_prob = 0.1,\n",
        "    num_labels = num_classes\n",
        ")   \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step3\", ignore_mismatched_sizes=True)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                  \n",
        "    train_dataset=train_dataset,         \n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics             \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UospXd4G2Oq",
        "outputId": "5a976221-d253-4912-9423-8e9921335ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"AutoModelForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading configuration file /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step3/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"/gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step3\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step3/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
            "\n",
            "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step3.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kor-semeval data로 학습된 Xlm-RoBERTa-base 모델 불러오기\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig, Trainer, TrainingArguments\n",
        "from transformers import logging\n",
        "logging.set_verbosity_debug()\n",
        "\n",
        "\n",
        "epochs = 2\n",
        "batch_size = 24\n",
        "num_steps = len(train_dataset) * epochs // batch_size\n",
        "warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = f'{base_dir}/models/{dataset_type}/BERT-pair/{task}/',          \n",
        "    num_train_epochs = epochs,              \n",
        "    per_device_train_batch_size = batch_size,  \n",
        "    per_device_eval_batch_size = batch_size,   \n",
        "    warmup_steps = warmup_steps,   \n",
        "    weight_decay = 0.01,               \n",
        "    logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-pair/{task}/',            \n",
        "    logging_steps = 10,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    learning_rate = 2e-5,\n",
        "    save_steps = save_steps\n",
        ")\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    'xlm-roberta-base',\n",
        "    architectures = ['AutoModelForSequenceClassification'],\n",
        "    hidden_size = 768,\n",
        "    num_hidden_layers = 12,\n",
        "    num_attention_heads = 12,\n",
        "    hidden_dropout_prob = 0.1,\n",
        "    num_labels = num_classes\n",
        ")    \n",
        "#kor-semeval data로 학습된 Xlm-RoBERTa-base 모델 불러오기\n",
        "model = AutoModelForSequenceClassification.from_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-pair/{task}/last_step2\", num_labels = 5, ignore_mismatched_sizes=True)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                  \n",
        "    train_dataset=train_dataset,         \n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics             \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLHzZoZdRFs-",
        "outputId": "6b542312-8c65-4794-b17a-3b7bb722cb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"AutoModelForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading configuration file /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step2/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"/gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step2\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step2/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
            "\n",
            "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-pair/NLI_M_Kor/last_step2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#메모리 에러뜰 때 캐시삭제\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "KtpPBKd45Y_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil\n",
        "\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "gpu_usage()    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6v08XXgUctZ",
        "outputId": "5786c51d-550a-48cb-deb5-4b0974b26991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=b6cf27396737ea0161fc6542feab18242abf2d22f1388474e2ece778e8684a0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 99% |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil\n",
        "\n",
        "import torch\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "def free_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()                             \n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "free_gpu_cache()   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8MfrIYDUmXg",
        "outputId": "3e44de6b-a16e-45ed-93a3-1ec2060e4a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Initial GPU Usage\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 99% |\n",
            "GPU Usage after emptying the cache\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  9% |  1% |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_result = trainer.evaluate(test_dataset)\n",
        "print(evaluation_result)"
      ],
      "metadata": {
        "id": "KNvdSkvY1Lsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'eval_P': 0.8177083333333334, 'eval_R': 0.615686274509804, 'eval_F1': 0.7024608501118568, \n",
        "\n",
        "'eval_4-way': 0.6039215686274509, \n",
        "'eval_3-way': 0.6045142296368989, 'eval_binary': 0.6190954773869347"
      ],
      "metadata": {
        "id": "tICT4mI4dKpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_result2 = trainer.evaluate(train_dataset)\n",
        "print(evaluation_result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "JprIu8_wNt72",
        "outputId": "09d7c184-bbb4-4518-c600-900f74c0667a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 15225\n",
            "  Batch size = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6410' max='1335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1335/1335 25:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.8320017457008362, 'eval_P': 0.8153846153846154, 'eval_R': 0.6235294117647059, 'eval_F1': 0.7066666666666667, 'eval_4-way': 0.6039215686274509, 'eval_3-way': 0.6045142296368989, 'eval_binary': 0.6190954773869347, 'eval_runtime': 483.4135, 'eval_samples_per_second': 31.495, 'eval_steps_per_second': 10.498}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "\n",
        "results\n",
        "\n",
        "scores = [softmax(prediction) for prediction in results.predictions]\n",
        "predicted_labels = [np.argmax(x) for x in scores]\n",
        "pd.DataFrame(predicted_labels).to_csv('KR3_train_pred.csv', index=False)\n",
        "#kakao_pred_tb = pd.read_csv('/content/kakap_pred.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "lOMX4xZwJLxN",
        "outputId": "b2c41724-39a9-4c81-d961-93fabe3311d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 4005\n",
            "  Batch size = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Q1VtM2Z6Q8",
        "outputId": "d11349cb-4094-4590-bda2-d1b73c890432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.18394557, 0.09541393, 0.4855529 , 0.08760048, 0.14748707],\n",
              "       dtype=float32),\n",
              " array([0.10513424, 0.08751103, 0.10061742, 0.00868727, 0.69805   ],\n",
              "       dtype=float32),\n",
              " array([0.2480254 , 0.07801297, 0.39909217, 0.06966891, 0.2052005 ],\n",
              "       dtype=float32),\n",
              " array([0.01199349, 0.00272463, 0.01279729, 0.0014536 , 0.97103083],\n",
              "       dtype=float32),\n",
              " array([6.5558339e-03, 1.7432400e-03, 8.9583220e-03, 9.4702246e-04,\n",
              "        9.8179567e-01], dtype=float32),\n",
              " array([4.8142388e-03, 1.1450469e-03, 3.4104777e-03, 5.4641376e-04,\n",
              "        9.9008358e-01], dtype=float32),\n",
              " array([0.2974245 , 0.04708086, 0.02322973, 0.00512534, 0.62713945],\n",
              "       dtype=float32),\n",
              " array([1.0588867e-02, 1.7170060e-03, 4.7836578e-03, 7.3275575e-04,\n",
              "        9.8217779e-01], dtype=float32),\n",
              " array([0.39406154, 0.01292406, 0.02303229, 0.0077755 , 0.5622065 ],\n",
              "       dtype=float32),\n",
              " array([5.6186486e-03, 1.2431013e-03, 3.8443285e-03, 5.7377946e-04,\n",
              "        9.8872018e-01], dtype=float32),\n",
              " array([0.05094185, 0.05741995, 0.7345766 , 0.05915107, 0.09791034],\n",
              "       dtype=float32),\n",
              " array([0.00835225, 0.00471455, 0.01098946, 0.0010269 , 0.9749169 ],\n",
              "       dtype=float32),\n",
              " array([0.07566398, 0.05994137, 0.7099383 , 0.0615073 , 0.09294923],\n",
              "       dtype=float32),\n",
              " array([0.05591716, 0.05740422, 0.71601474, 0.05873577, 0.11192798],\n",
              "       dtype=float32),\n",
              " array([0.00781292, 0.00257424, 0.01525376, 0.00139779, 0.9729613 ],\n",
              "       dtype=float32),\n",
              " array([3.2772669e-03, 1.1752169e-03, 5.2040657e-03, 6.4131385e-04,\n",
              "        9.8970217e-01], dtype=float32),\n",
              " array([0.08851317, 0.13264479, 0.64701355, 0.07652532, 0.05530311],\n",
              "       dtype=float32),\n",
              " array([6.3029011e-03, 1.8589959e-03, 8.2386658e-03, 9.4185618e-04,\n",
              "        9.8265743e-01], dtype=float32),\n",
              " array([0.00688031, 0.00248674, 0.01982056, 0.00175077, 0.96906173],\n",
              "       dtype=float32),\n",
              " array([4.0598102e-03, 1.3833215e-03, 6.6355667e-03, 7.4971031e-04,\n",
              "        9.8717165e-01], dtype=float32),\n",
              " array([4.6846978e-03, 1.1002071e-03, 3.6356575e-03, 5.5990607e-04,\n",
              "        9.9001944e-01], dtype=float32),\n",
              " array([0.4322418 , 0.06509576, 0.03057759, 0.00806948, 0.4640156 ],\n",
              "       dtype=float32),\n",
              " array([1.0015175e-02, 1.5532307e-03, 4.8424378e-03, 7.1229780e-04,\n",
              "        9.8287684e-01], dtype=float32),\n",
              " array([0.8570766 , 0.0168322 , 0.02942305, 0.01881697, 0.07785113],\n",
              "       dtype=float32),\n",
              " array([5.8890069e-03, 1.2276489e-03, 4.3119462e-03, 6.0970086e-04,\n",
              "        9.8796177e-01], dtype=float32),\n",
              " array([4.7400645e-03, 1.1013036e-03, 3.5111771e-03, 5.5568368e-04,\n",
              "        9.9009162e-01], dtype=float32),\n",
              " array([0.16357568, 0.03365348, 0.02314535, 0.00475645, 0.7748689 ],\n",
              "       dtype=float32),\n",
              " array([1.8943587e-02, 2.0201777e-03, 6.2248968e-03, 9.5139019e-04,\n",
              "        9.7186005e-01], dtype=float32),\n",
              " array([0.6779992 , 0.01675845, 0.02975717, 0.01449494, 0.2609903 ],\n",
              "       dtype=float32),\n",
              " array([5.9769498e-03, 1.2112302e-03, 4.2297440e-03, 6.0625910e-04,\n",
              "        9.8797596e-01], dtype=float32),\n",
              " array([3.0590559e-03, 1.1024323e-03, 4.7842097e-03, 5.9765851e-04,\n",
              "        9.9045664e-01], dtype=float32),\n",
              " array([0.05878178, 0.0739423 , 0.71868724, 0.05817845, 0.09041029],\n",
              "       dtype=float32),\n",
              " array([0.01140142, 0.00339633, 0.0220894 , 0.00195251, 0.96116036],\n",
              "       dtype=float32),\n",
              " array([0.02271626, 0.00854178, 0.10701811, 0.00735185, 0.8543719 ],\n",
              "       dtype=float32),\n",
              " array([4.0533072e-03, 1.3576782e-03, 7.6006223e-03, 7.7718322e-04,\n",
              "        9.8621148e-01], dtype=float32),\n",
              " array([0.00688931, 0.00256997, 0.01547318, 0.00150092, 0.9735665 ],\n",
              "       dtype=float32),\n",
              " array([0.01435783, 0.00890781, 0.01648211, 0.00159509, 0.9586571 ],\n",
              "       dtype=float32),\n",
              " array([0.0098722 , 0.00270922, 0.01198719, 0.00128546, 0.974146  ],\n",
              "       dtype=float32),\n",
              " array([0.08365113, 0.05436216, 0.652531  , 0.0603456 , 0.14911003],\n",
              "       dtype=float32),\n",
              " array([0.08481418, 0.03696244, 0.41035753, 0.02959438, 0.4382715 ],\n",
              "       dtype=float32),\n",
              " array([5.8385134e-03, 1.1113802e-03, 3.8515653e-03, 6.1433925e-04,\n",
              "        9.8858440e-01], dtype=float32),\n",
              " array([8.6018881e-03, 2.0230561e-03, 4.8238509e-03, 6.6224736e-04,\n",
              "        9.8388910e-01], dtype=float32),\n",
              " array([0.2777473 , 0.00868769, 0.0209772 , 0.0052688 , 0.68731916],\n",
              "       dtype=float32),\n",
              " array([0.91597235, 0.01504903, 0.02216575, 0.02145394, 0.02535897],\n",
              "       dtype=float32),\n",
              " array([1.0550664e-02, 1.4732152e-03, 6.0368646e-03, 8.2890614e-04,\n",
              "        9.8111051e-01], dtype=float32),\n",
              " array([4.9043079e-03, 1.0751616e-03, 3.5779742e-03, 5.5889331e-04,\n",
              "        9.8988390e-01], dtype=float32),\n",
              " array([1.3825665e-02, 3.4906806e-03, 7.2156885e-03, 8.7111519e-04,\n",
              "        9.7459668e-01], dtype=float32),\n",
              " array([8.4798308e-03, 1.3417045e-03, 4.4922219e-03, 6.6409091e-04,\n",
              "        9.8502237e-01], dtype=float32),\n",
              " array([0.9127747 , 0.0153802 , 0.02414944, 0.02488718, 0.02280841],\n",
              "       dtype=float32),\n",
              " array([8.1924088e-03, 1.4312683e-03, 5.9580696e-03, 7.6164800e-04,\n",
              "        9.8365653e-01], dtype=float32),\n",
              " array([4.3262453e-03, 1.1260186e-03, 3.7330259e-03, 5.5400503e-04,\n",
              "        9.9026066e-01], dtype=float32),\n",
              " array([0.91899115, 0.03283102, 0.01825858, 0.01934665, 0.01057262],\n",
              "       dtype=float32),\n",
              " array([6.5658572e-03, 1.3615836e-03, 4.3046353e-03, 6.1199465e-04,\n",
              "        9.8715574e-01], dtype=float32),\n",
              " array([1.2448228e-02, 1.8840724e-03, 5.9251706e-03, 8.7502564e-04,\n",
              "        9.7886747e-01], dtype=float32),\n",
              " array([5.1041106e-03, 1.2048711e-03, 4.1742171e-03, 5.7840045e-04,\n",
              "        9.8893845e-01], dtype=float32),\n",
              " array([0.7062287 , 0.0543192 , 0.12152188, 0.07472519, 0.04320503],\n",
              "       dtype=float32),\n",
              " array([0.02526831, 0.00974724, 0.0150166 , 0.00160336, 0.9483645 ],\n",
              "       dtype=float32),\n",
              " array([0.33374852, 0.03235816, 0.12917334, 0.0265564 , 0.47816357],\n",
              "       dtype=float32),\n",
              " array([0.69699776, 0.05699174, 0.1263112 , 0.07625558, 0.04344369],\n",
              "       dtype=float32),\n",
              " array([0.03423273, 0.00605373, 0.03214267, 0.00346557, 0.9241054 ],\n",
              "       dtype=float32),\n",
              " array([4.9998378e-03, 1.1826220e-03, 4.0387493e-03, 5.9660443e-04,\n",
              "        9.8918235e-01], dtype=float32),\n",
              " array([6.8569928e-03, 1.7707933e-03, 4.5566149e-03, 6.1054219e-04,\n",
              "        9.8620528e-01], dtype=float32),\n",
              " array([0.9380147 , 0.01090242, 0.01443609, 0.01256269, 0.02408402],\n",
              "       dtype=float32),\n",
              " array([6.1799549e-03, 1.3369966e-03, 4.3736245e-03, 6.4091216e-04,\n",
              "        9.8746836e-01], dtype=float32),\n",
              " array([6.1510662e-03, 1.3098681e-03, 4.5322673e-03, 6.2783703e-04,\n",
              "        9.8737884e-01], dtype=float32),\n",
              " array([0.04775426, 0.04406215, 0.75687754, 0.05507864, 0.0962273 ],\n",
              "       dtype=float32),\n",
              " array([0.01457601, 0.01120519, 0.02129791, 0.00167345, 0.9512474 ],\n",
              "       dtype=float32),\n",
              " array([0.05961929, 0.04250804, 0.74647367, 0.05274079, 0.09865829],\n",
              "       dtype=float32),\n",
              " array([0.01658585, 0.00685617, 0.06627035, 0.00451734, 0.90577036],\n",
              "       dtype=float32),\n",
              " array([0.01268524, 0.00485245, 0.03377326, 0.002678  , 0.94601107],\n",
              "       dtype=float32),\n",
              " array([5.6895665e-03, 1.1196387e-03, 3.9844299e-03, 6.4358691e-04,\n",
              "        9.8856276e-01], dtype=float32),\n",
              " array([7.0934966e-03, 1.7707293e-03, 4.5491685e-03, 6.3779089e-04,\n",
              "        9.8594856e-01], dtype=float32),\n",
              " array([0.9384637 , 0.01298865, 0.01749766, 0.0228348 , 0.00821518],\n",
              "       dtype=float32),\n",
              " array([0.08582407, 0.00475347, 0.01341694, 0.0028094 , 0.89319605],\n",
              "       dtype=float32),\n",
              " array([7.0798681e-03, 1.2390523e-03, 4.8559252e-03, 6.9142925e-04,\n",
              "        9.8613381e-01], dtype=float32),\n",
              " array([0.46149707, 0.09101024, 0.25942713, 0.12788577, 0.0601796 ],\n",
              "       dtype=float32),\n",
              " array([7.8160353e-03, 2.7020064e-03, 6.2045618e-03, 7.4617879e-04,\n",
              "        9.8253137e-01], dtype=float32),\n",
              " array([0.73819923, 0.04723912, 0.11226995, 0.05877298, 0.04351875],\n",
              "       dtype=float32),\n",
              " array([1.0516438e-02, 2.0038525e-03, 6.7199208e-03, 8.9793210e-04,\n",
              "        9.7986174e-01], dtype=float32),\n",
              " array([5.2653519e-03, 1.3148016e-03, 4.9665994e-03, 6.4900151e-04,\n",
              "        9.8780400e-01], dtype=float32),\n",
              " array([3.3539080e-03, 1.1495700e-03, 4.8305076e-03, 6.1709556e-04,\n",
              "        9.9004865e-01], dtype=float32),\n",
              " array([0.11378065, 0.21024981, 0.24989167, 0.01937398, 0.406704  ],\n",
              "       dtype=float32),\n",
              " array([0.00762002, 0.00214062, 0.00929938, 0.00100285, 0.979937  ],\n",
              "       dtype=float32),\n",
              " array([0.10490064, 0.08371891, 0.60436964, 0.0917489 , 0.11526185],\n",
              "       dtype=float32),\n",
              " array([0.00658188, 0.00193365, 0.00968815, 0.00101519, 0.98078126],\n",
              "       dtype=float32),\n",
              " array([4.0571378e-03, 1.2319168e-03, 5.3703180e-03, 6.5254344e-04,\n",
              "        9.8868811e-01], dtype=float32),\n",
              " array([0.04227171, 0.03463903, 0.0392224 , 0.0034098 , 0.8804571 ],\n",
              "       dtype=float32),\n",
              " array([0.22125243, 0.04235272, 0.19261476, 0.03057547, 0.5132047 ],\n",
              "       dtype=float32),\n",
              " array([0.25541362, 0.08645464, 0.45087922, 0.10244605, 0.10480649],\n",
              "       dtype=float32),\n",
              " array([0.07883296, 0.02445468, 0.16712613, 0.01569869, 0.71388745],\n",
              "       dtype=float32),\n",
              " array([5.3499574e-03, 1.3122911e-03, 4.5436835e-03, 6.3327979e-04,\n",
              "        9.8816061e-01], dtype=float32),\n",
              " array([0.03708968, 0.01029294, 0.01343739, 0.00159031, 0.9375897 ],\n",
              "       dtype=float32),\n",
              " array([0.04084039, 0.00544338, 0.01778029, 0.00236397, 0.93357193],\n",
              "       dtype=float32),\n",
              " array([0.13917655, 0.00715584, 0.02123359, 0.00404621, 0.82838774],\n",
              "       dtype=float32),\n",
              " array([8.3856145e-03, 1.7302879e-03, 6.7723938e-03, 8.3507434e-04,\n",
              "        9.8227662e-01], dtype=float32),\n",
              " array([0.60637844, 0.06014312, 0.1921953 , 0.09454698, 0.04673608],\n",
              "       dtype=float32),\n",
              " array([0.02024382, 0.00643621, 0.01050326, 0.00117574, 0.96164113],\n",
              "       dtype=float32),\n",
              " array([0.7990973 , 0.03322542, 0.08736487, 0.04737713, 0.0329352 ],\n",
              "       dtype=float32),\n",
              " array([0.01928615, 0.00259164, 0.00939128, 0.00131754, 0.9674135 ],\n",
              "       dtype=float32),\n",
              " array([6.4916280e-03, 1.3708951e-03, 5.6011383e-03, 7.2645012e-04,\n",
              "        9.8580992e-01], dtype=float32),\n",
              " array([3.5483940e-03, 1.0152643e-03, 4.3346351e-03, 6.0630625e-04,\n",
              "        9.9049538e-01], dtype=float32),\n",
              " array([5.2829385e-03, 1.7979668e-03, 5.1927748e-03, 6.2410417e-04,\n",
              "        9.8710197e-01], dtype=float32),\n",
              " array([0.36453232, 0.0945929 , 0.36282462, 0.13919231, 0.0388577 ],\n",
              "       dtype=float32),\n",
              " array([0.08078411, 0.01297843, 0.05526237, 0.00769874, 0.84327644],\n",
              "       dtype=float32),\n",
              " array([7.213728e-03, 1.614517e-03, 8.047607e-03, 8.964604e-04,\n",
              "        9.822278e-01], dtype=float32),\n",
              " array([4.6261474e-03, 1.4033548e-03, 5.1190858e-03, 6.9455360e-04,\n",
              "        9.8815686e-01], dtype=float32),\n",
              " array([0.08715952, 0.0529829 , 0.04286758, 0.00606717, 0.81092286],\n",
              "       dtype=float32),\n",
              " array([0.0164046 , 0.00311099, 0.0102722 , 0.00130687, 0.96890515],\n",
              "       dtype=float32),\n",
              " array([0.02776079, 0.00372267, 0.01122763, 0.00158736, 0.9557016 ],\n",
              "       dtype=float32),\n",
              " array([5.5376762e-03, 1.5278615e-03, 5.7200384e-03, 7.2053837e-04,\n",
              "        9.8649406e-01], dtype=float32),\n",
              " array([5.2917576e-03, 1.1640869e-03, 4.2315456e-03, 6.1576522e-04,\n",
              "        9.8869711e-01], dtype=float32),\n",
              " array([1.0640174e-02, 2.7725517e-03, 5.8807568e-03, 7.4893993e-04,\n",
              "        9.7995752e-01], dtype=float32),\n",
              " array([0.9155533 , 0.01618191, 0.02574919, 0.01954203, 0.02297377],\n",
              "       dtype=float32),\n",
              " array([0.01761711, 0.00223745, 0.00760666, 0.00112773, 0.97141105],\n",
              "       dtype=float32),\n",
              " array([7.6501709e-03, 1.4575515e-03, 5.8255624e-03, 7.4611261e-04,\n",
              "        9.8432082e-01], dtype=float32),\n",
              " array([4.8675369e-03, 1.1404973e-03, 3.6728382e-03, 5.5211521e-04,\n",
              "        9.8976690e-01], dtype=float32),\n",
              " array([1.6106484e-02, 4.3606055e-03, 7.0888270e-03, 8.4579870e-04,\n",
              "        9.7159821e-01], dtype=float32),\n",
              " array([0.8982187 , 0.0115957 , 0.02133761, 0.01193647, 0.05691155],\n",
              "       dtype=float32),\n",
              " array([7.4065556e-03, 1.3905924e-03, 4.5171855e-03, 6.5451598e-04,\n",
              "        9.8603123e-01], dtype=float32),\n",
              " array([5.6233048e-03, 1.2289908e-03, 4.1041067e-03, 5.7482067e-04,\n",
              "        9.8846889e-01], dtype=float32),\n",
              " array([5.2860682e-03, 1.1067159e-03, 3.7218144e-03, 5.9269369e-04,\n",
              "        9.8929274e-01], dtype=float32),\n",
              " array([0.20989527, 0.04199344, 0.02712149, 0.00534007, 0.71564966],\n",
              "       dtype=float32),\n",
              " array([1.2908856e-02, 1.7012373e-03, 5.2929339e-03, 8.0381264e-04,\n",
              "        9.7929329e-01], dtype=float32),\n",
              " array([0.8820055 , 0.01875485, 0.03047804, 0.02217594, 0.04658563],\n",
              "       dtype=float32),\n",
              " array([7.3103667e-03, 1.2953839e-03, 4.7599850e-03, 6.8574050e-04,\n",
              "        9.8594856e-01], dtype=float32),\n",
              " array([4.4603990e-03, 1.0522406e-03, 3.8460321e-03, 5.8903772e-04,\n",
              "        9.9005252e-01], dtype=float32),\n",
              " array([6.4675929e-03, 1.8265124e-03, 4.6604169e-03, 6.2655221e-04,\n",
              "        9.8641872e-01], dtype=float32),\n",
              " array([0.9051439 , 0.01904496, 0.03381482, 0.03438721, 0.00760911],\n",
              "       dtype=float32),\n",
              " array([0.2838206 , 0.01089578, 0.03153333, 0.00794743, 0.6658029 ],\n",
              "       dtype=float32),\n",
              " array([7.1598124e-03, 1.3362706e-03, 5.4628300e-03, 7.2683953e-04,\n",
              "        9.8531413e-01], dtype=float32),\n",
              " array([5.2633337e-03, 1.1222771e-03, 3.8084290e-03, 6.4228330e-04,\n",
              "        9.8916394e-01], dtype=float32),\n",
              " array([0.02368242, 0.005303  , 0.00895929, 0.00119608, 0.9608592 ],\n",
              "       dtype=float32),\n",
              " array([1.0329430e-02, 1.4633845e-03, 4.8941667e-03, 7.6499366e-04,\n",
              "        9.8254788e-01], dtype=float32),\n",
              " array([0.91914403, 0.01598598, 0.02257119, 0.0289342 , 0.01336465],\n",
              "       dtype=float32),\n",
              " array([0.02067049, 0.00224897, 0.01070684, 0.0013814 , 0.96499246],\n",
              "       dtype=float32),\n",
              " array([3.1893742e-03, 1.1416175e-03, 5.4005710e-03, 6.4309791e-04,\n",
              "        9.8962522e-01], dtype=float32),\n",
              " array([5.2059572e-03, 2.3545157e-03, 6.5607838e-03, 6.9661799e-04,\n",
              "        9.8518211e-01], dtype=float32),\n",
              " array([0.06838273, 0.04571809, 0.7331872 , 0.05703757, 0.09567443],\n",
              "       dtype=float32),\n",
              " array([0.00657616, 0.00204141, 0.01116257, 0.00105512, 0.97916484],\n",
              "       dtype=float32),\n",
              " array([5.0222506e-03, 1.6782540e-03, 9.4352067e-03, 9.1297837e-04,\n",
              "        9.8295134e-01], dtype=float32),\n",
              " array([0.06436796, 0.04967064, 0.73250854, 0.06632622, 0.08712667],\n",
              "       dtype=float32),\n",
              " array([5.4206974e-03, 2.4819563e-03, 7.6615382e-03, 7.8252651e-04,\n",
              "        9.8365319e-01], dtype=float32),\n",
              " array([0.07743232, 0.0534399 , 0.7227248 , 0.07463788, 0.07176501],\n",
              "       dtype=float32),\n",
              " array([0.05008174, 0.03082442, 0.5874154 , 0.03535671, 0.2963217 ],\n",
              "       dtype=float32),\n",
              " array([0.02907744, 0.00958679, 0.10759988, 0.00683614, 0.8468997 ],\n",
              "       dtype=float32),\n",
              " array([0.84685975, 0.03023921, 0.05744047, 0.04784453, 0.017616  ],\n",
              "       dtype=float32),\n",
              " array([9.0256520e-03, 2.4402833e-03, 5.4947780e-03, 7.1626296e-04,\n",
              "        9.8232299e-01], dtype=float32),\n",
              " array([0.8923125 , 0.02256031, 0.04019811, 0.03413454, 0.01079456],\n",
              "       dtype=float32),\n",
              " array([6.0544214e-03, 1.1810447e-03, 4.1472549e-03, 6.4955885e-04,\n",
              "        9.8796803e-01], dtype=float32),\n",
              " array([7.7792592e-03, 1.4357824e-03, 6.0084653e-03, 7.7989663e-04,\n",
              "        9.8399657e-01], dtype=float32),\n",
              " array([5.0225118e-03, 1.1303341e-03, 3.9669643e-03, 6.0556771e-04,\n",
              "        9.8927480e-01], dtype=float32),\n",
              " array([6.4015496e-03, 1.7976196e-03, 4.4331690e-03, 6.1119237e-04,\n",
              "        9.8675662e-01], dtype=float32),\n",
              " array([0.9271594 , 0.01702521, 0.0221454 , 0.02408312, 0.0095868 ],\n",
              "       dtype=float32),\n",
              " array([7.2134114e-03, 1.3421872e-03, 4.1912021e-03, 6.5964687e-04,\n",
              "        9.8659331e-01], dtype=float32),\n",
              " array([6.0461299e-03, 1.2455856e-03, 4.4577154e-03, 6.3170184e-04,\n",
              "        9.8761892e-01], dtype=float32),\n",
              " array([5.3630350e-03, 1.1625071e-03, 4.1801371e-03, 6.1454083e-04,\n",
              "        9.8867959e-01], dtype=float32),\n",
              " array([6.7494009e-03, 1.8071198e-03, 4.5750118e-03, 6.2283472e-04,\n",
              "        9.8624575e-01], dtype=float32),\n",
              " array([0.9391244 , 0.01326847, 0.01842024, 0.01879062, 0.01039635],\n",
              "       dtype=float32),\n",
              " array([8.3477460e-03, 1.4687661e-03, 4.8934878e-03, 7.2463654e-04,\n",
              "        9.8456544e-01], dtype=float32),\n",
              " array([6.1177262e-03, 1.2544334e-03, 4.5473943e-03, 6.3212548e-04,\n",
              "        9.8744845e-01], dtype=float32),\n",
              " array([6.8417867e-03, 1.2232186e-03, 4.0358207e-03, 6.2893907e-04,\n",
              "        9.8727006e-01], dtype=float32),\n",
              " array([0.02775875, 0.00550852, 0.00805973, 0.00116766, 0.9575052 ],\n",
              "       dtype=float32),\n",
              " array([0.94299376, 0.01242217, 0.01440055, 0.01854698, 0.01163649],\n",
              "       dtype=float32),\n",
              " array([9.3413005e-03, 1.4574500e-03, 4.3718121e-03, 7.0620107e-04,\n",
              "        9.8412329e-01], dtype=float32),\n",
              " array([0.01689092, 0.00196199, 0.00734954, 0.00102432, 0.9727733 ],\n",
              "       dtype=float32),\n",
              " array([6.5728682e-03, 1.1945232e-03, 4.0324177e-03, 6.3263025e-04,\n",
              "        9.8756754e-01], dtype=float32),\n",
              " array([9.3912454e-03, 2.0880473e-03, 4.8371553e-03, 6.7671674e-04,\n",
              "        9.8300713e-01], dtype=float32),\n",
              " array([0.9420653 , 0.01361464, 0.01496345, 0.02154849, 0.00780822],\n",
              "       dtype=float32),\n",
              " array([0.02298377, 0.0023684 , 0.00633466, 0.00108652, 0.96722674],\n",
              "       dtype=float32),\n",
              " array([8.8332240e-03, 1.3825671e-03, 4.8336806e-03, 7.0240616e-04,\n",
              "        9.8424816e-01], dtype=float32),\n",
              " array([4.6424423e-03, 1.1345297e-03, 3.5494738e-03, 5.5189099e-04,\n",
              "        9.9012184e-01], dtype=float32),\n",
              " array([1.4304345e-02, 3.4780467e-03, 5.9347451e-03, 8.0058264e-04,\n",
              "        9.7548240e-01], dtype=float32),\n",
              " array([0.94455516, 0.01271587, 0.01391126, 0.01735256, 0.0114652 ],\n",
              "       dtype=float32),\n",
              " array([5.6749131e-03, 1.2438537e-03, 3.6032195e-03, 5.7383475e-04,\n",
              "        9.8890400e-01], dtype=float32),\n",
              " array([5.5582393e-03, 1.2371660e-03, 3.9495169e-03, 5.7727244e-04,\n",
              "        9.8867774e-01], dtype=float32),\n",
              " array([3.7283048e-03, 1.0911352e-03, 5.0588031e-03, 6.5291376e-04,\n",
              "        9.8946857e-01], dtype=float32),\n",
              " array([8.2962858e-03, 3.1350397e-03, 7.9313749e-03, 8.4740459e-04,\n",
              "        9.7978985e-01], dtype=float32),\n",
              " array([0.34776023, 0.08146503, 0.3832967 , 0.10295741, 0.08452055],\n",
              "       dtype=float32),\n",
              " array([0.27416468, 0.06818998, 0.32885808, 0.07746456, 0.25132275],\n",
              "       dtype=float32),\n",
              " array([0.32870844, 0.08478824, 0.40620705, 0.14661251, 0.03368366],\n",
              "       dtype=float32),\n",
              " array([0.19770281, 0.07667255, 0.57857764, 0.07281332, 0.07423365],\n",
              "       dtype=float32),\n",
              " array([7.8836773e-03, 3.5693382e-03, 7.9827607e-03, 8.0750452e-04,\n",
              "        9.7975665e-01], dtype=float32),\n",
              " array([0.29177272, 0.07972813, 0.5104983 , 0.08283651, 0.03516428],\n",
              "       dtype=float32),\n",
              " array([4.6353815e-03, 1.2924675e-03, 5.2676215e-03, 6.7144085e-04,\n",
              "        9.8813325e-01], dtype=float32),\n",
              " array([0.00731067, 0.00189138, 0.00978505, 0.00100704, 0.9800056 ],\n",
              "       dtype=float32),\n",
              " array([3.4878755e-03, 1.2445870e-03, 5.8358382e-03, 6.7668961e-04,\n",
              "        9.8875505e-01], dtype=float32),\n",
              " array([0.03681434, 0.04255665, 0.0602091 , 0.00479652, 0.8556233 ],\n",
              "       dtype=float32),\n",
              " array([0.08128214, 0.06407111, 0.68790656, 0.07303865, 0.09370159],\n",
              "       dtype=float32),\n",
              " array([0.02618174, 0.01116143, 0.08938044, 0.00715743, 0.86611897],\n",
              "       dtype=float32),\n",
              " array([0.07031951, 0.05042432, 0.72417444, 0.06239112, 0.09269057],\n",
              "       dtype=float32),\n",
              " array([0.00493096, 0.00195234, 0.01546708, 0.00132113, 0.9763284 ],\n",
              "       dtype=float32),\n",
              " array([0.01442372, 0.01069186, 0.02541794, 0.00214247, 0.947324  ],\n",
              "       dtype=float32),\n",
              " array([0.07048243, 0.04582513, 0.69924575, 0.06663209, 0.11781472],\n",
              "       dtype=float32),\n",
              " array([0.05595486, 0.04078386, 0.70391315, 0.05958616, 0.13976212],\n",
              "       dtype=float32),\n",
              " array([0.07415868, 0.05367357, 0.7139329 , 0.08975065, 0.06848422],\n",
              "       dtype=float32),\n",
              " array([0.05774302, 0.04548069, 0.75423944, 0.06308662, 0.07945012],\n",
              "       dtype=float32),\n",
              " array([0.01365684, 0.0092053 , 0.01700139, 0.00138643, 0.95874995],\n",
              "       dtype=float32),\n",
              " array([0.01094694, 0.00300798, 0.0161992 , 0.00157935, 0.96826637],\n",
              "       dtype=float32),\n",
              " array([0.00717811, 0.00205432, 0.01169697, 0.00115414, 0.97791624],\n",
              "       dtype=float32),\n",
              " array([0.07303295, 0.04792111, 0.7609879 , 0.07964389, 0.03841423],\n",
              "       dtype=float32),\n",
              " array([5.4775910e-03, 1.1060670e-03, 4.1834209e-03, 6.4488815e-04,\n",
              "        9.8858815e-01], dtype=float32),\n",
              " array([8.8643171e-03, 2.1413856e-03, 5.2095302e-03, 7.3253288e-04,\n",
              "        9.8305207e-01], dtype=float32),\n",
              " array([0.92149866, 0.01693527, 0.02700888, 0.02677118, 0.00778605],\n",
              "       dtype=float32),\n",
              " array([7.7100103e-03, 1.2961482e-03, 4.5660045e-03, 7.3735329e-04,\n",
              "        9.8569041e-01], dtype=float32),\n",
              " array([9.5687797e-03, 1.4701737e-03, 6.2441612e-03, 8.2050788e-04,\n",
              "        9.8189640e-01], dtype=float32),\n",
              " array([0.05363012, 0.04684484, 0.7659954 , 0.07397567, 0.05955396],\n",
              "       dtype=float32),\n",
              " array([4.5739631e-03, 1.9657000e-03, 6.1535398e-03, 6.7644310e-04,\n",
              "        9.8663050e-01], dtype=float32),\n",
              " array([0.06049588, 0.0473997 , 0.7608252 , 0.07111027, 0.06016902],\n",
              "       dtype=float32),\n",
              " array([4.2223521e-03, 1.2958923e-03, 6.0472516e-03, 7.1396696e-04,\n",
              "        9.8772073e-01], dtype=float32),\n",
              " array([4.3526692e-03, 1.4045825e-03, 7.7188788e-03, 7.8887085e-04,\n",
              "        9.8573518e-01], dtype=float32),\n",
              " array([4.8488081e-03, 1.1275122e-03, 3.8826528e-03, 5.9000024e-04,\n",
              "        9.8955119e-01], dtype=float32),\n",
              " array([1.2715439e-02, 3.4395659e-03, 6.9020595e-03, 8.7817607e-04,\n",
              "        9.7606492e-01], dtype=float32),\n",
              " array([0.9382688 , 0.01315371, 0.01784972, 0.0193659 , 0.0113619 ],\n",
              "       dtype=float32),\n",
              " array([0.92774826, 0.01564434, 0.01985465, 0.02995963, 0.0067929 ],\n",
              "       dtype=float32),\n",
              " array([8.1605623e-03, 1.5346877e-03, 5.6708208e-03, 7.6864066e-04,\n",
              "        9.8386520e-01], dtype=float32),\n",
              " array([0.0700289 , 0.05047298, 0.74482167, 0.08648884, 0.04818768],\n",
              "       dtype=float32),\n",
              " array([4.1383454e-03, 1.7181460e-03, 5.0944118e-03, 5.9725903e-04,\n",
              "        9.8845190e-01], dtype=float32),\n",
              " array([0.07842524, 0.04895107, 0.7413393 , 0.08227521, 0.04900921],\n",
              "       dtype=float32),\n",
              " array([4.0753852e-03, 1.3327490e-03, 6.6463109e-03, 7.6408806e-04,\n",
              "        9.8718154e-01], dtype=float32),\n",
              " array([4.4025495e-03, 1.3919563e-03, 7.4522053e-03, 7.6598575e-04,\n",
              "        9.8598713e-01], dtype=float32),\n",
              " array([0.14527704, 0.06673472, 0.6068814 , 0.08487262, 0.09623425],\n",
              "       dtype=float32),\n",
              " array([7.1678916e-03, 3.0685752e-03, 8.0912560e-03, 8.1307517e-04,\n",
              "        9.8085940e-01], dtype=float32),\n",
              " array([0.17490548, 0.07027231, 0.5776285 , 0.08560099, 0.09159269],\n",
              "       dtype=float32),\n",
              " array([4.6339491e-03, 1.2821623e-03, 5.8371769e-03, 7.1459851e-04,\n",
              "        9.8753184e-01], dtype=float32),\n",
              " array([0.16992523, 0.05075477, 0.47792485, 0.0562702 , 0.24512492],\n",
              "       dtype=float32),\n",
              " array([0.06011558, 0.05373889, 0.7477956 , 0.07288992, 0.06546018],\n",
              "       dtype=float32),\n",
              " array([0.01631773, 0.01068601, 0.01719773, 0.00163113, 0.95416754],\n",
              "       dtype=float32),\n",
              " array([6.9938763e-03, 1.8571301e-03, 8.9481054e-03, 9.4388955e-04,\n",
              "        9.8125702e-01], dtype=float32),\n",
              " array([3.5676234e-03, 1.1460917e-03, 4.7425488e-03, 6.2511978e-04,\n",
              "        9.8991889e-01], dtype=float32),\n",
              " array([4.8961043e-03, 1.5399306e-03, 8.0407867e-03, 8.4641395e-04,\n",
              "        9.8467678e-01], dtype=float32),\n",
              " array([0.06950011, 0.06832864, 0.6458426 , 0.06540915, 0.15091944],\n",
              "       dtype=float32),\n",
              " array([6.8108048e-03, 3.5591717e-03, 8.8738156e-03, 8.9789095e-04,\n",
              "        9.7985852e-01], dtype=float32),\n",
              " array([0.0883978 , 0.06810211, 0.6461839 , 0.06803126, 0.12928492],\n",
              "       dtype=float32),\n",
              " array([5.2148714e-03, 1.8018531e-03, 9.0301335e-03, 9.2923158e-04,\n",
              "        9.8302394e-01], dtype=float32),\n",
              " array([0.00792712, 0.00278138, 0.01507458, 0.00138346, 0.97283375],\n",
              "       dtype=float32),\n",
              " array([0.05018753, 0.05095697, 0.72179496, 0.05032378, 0.12673667],\n",
              "       dtype=float32),\n",
              " array([0.0796508 , 0.16015165, 0.15523948, 0.01178813, 0.5931699 ],\n",
              "       dtype=float32),\n",
              " array([0.13224   , 0.06081588, 0.5766455 , 0.05120265, 0.17909598],\n",
              "       dtype=float32),\n",
              " array([4.2890655e-03, 1.3328037e-03, 5.6499294e-03, 6.8792823e-04,\n",
              "        9.8804009e-01], dtype=float32),\n",
              " array([0.02697017, 0.00906749, 0.0630248 , 0.00508174, 0.8958557 ],\n",
              "       dtype=float32),\n",
              " array([0.20870823, 0.07236044, 0.54826987, 0.12468131, 0.04598014],\n",
              "       dtype=float32),\n",
              " array([4.4743665e-03, 1.5040967e-03, 4.5527751e-03, 5.8144395e-04,\n",
              "        9.8888755e-01], dtype=float32),\n",
              " array([0.34742436, 0.07566184, 0.40967748, 0.1190934 , 0.04814296],\n",
              "       dtype=float32),\n",
              " array([5.0868699e-03, 1.2912261e-03, 4.9836873e-03, 6.5980264e-04,\n",
              "        9.8797840e-01], dtype=float32),\n",
              " array([5.1785023e-03, 1.3617135e-03, 5.4592132e-03, 6.8392034e-04,\n",
              "        9.8731673e-01], dtype=float32),\n",
              " array([5.5346293e-03, 1.1306715e-03, 3.8902310e-03, 6.7985174e-04,\n",
              "        9.8876446e-01], dtype=float32),\n",
              " array([1.2206659e-02, 2.4962144e-03, 5.8125323e-03, 8.2446041e-04,\n",
              "        9.7866029e-01], dtype=float32),\n",
              " array([0.9281875 , 0.01139321, 0.01903016, 0.01394933, 0.02743995],\n",
              "       dtype=float32),\n",
              " array([0.9311541 , 0.01370179, 0.02044551, 0.02074417, 0.0139545 ],\n",
              "       dtype=float32),\n",
              " array([1.1930244e-02, 1.5456753e-03, 6.5016835e-03, 9.1543526e-04,\n",
              "        9.7910702e-01], dtype=float32),\n",
              " array([5.7983971e-03, 1.1300948e-03, 4.0115304e-03, 6.2259776e-04,\n",
              "        9.8843724e-01], dtype=float32),\n",
              " array([1.0377397e-02, 2.3634234e-03, 5.4449821e-03, 7.2127202e-04,\n",
              "        9.8109281e-01], dtype=float32),\n",
              " array([0.9411251 , 0.01275987, 0.01588922, 0.01852296, 0.01170273],\n",
              "       dtype=float32),\n",
              " array([0.9184513 , 0.01386908, 0.02020566, 0.01930322, 0.02817073],\n",
              "       dtype=float32),\n",
              " array([8.8609112e-03, 1.3900191e-03, 5.2231089e-03, 7.3620514e-04,\n",
              "        9.8378962e-01], dtype=float32),\n",
              " array([7.0684194e-03, 1.2783201e-03, 4.2672926e-03, 6.6283083e-04,\n",
              "        9.8672318e-01], dtype=float32),\n",
              " array([1.0665812e-02, 2.3920536e-03, 5.4043038e-03, 7.4183143e-04,\n",
              "        9.8079622e-01], dtype=float32),\n",
              " array([0.03366335, 0.00309253, 0.00878843, 0.00141842, 0.9530372 ],\n",
              "       dtype=float32),\n",
              " array([0.93295866, 0.01416253, 0.01830633, 0.02181227, 0.01276013],\n",
              "       dtype=float32),\n",
              " array([8.8949893e-03, 1.4981619e-03, 5.3313803e-03, 7.4587646e-04,\n",
              "        9.8352987e-01], dtype=float32),\n",
              " array([0.92103755, 0.0146206 , 0.01956841, 0.02001818, 0.02475526],\n",
              "       dtype=float32),\n",
              " array([7.4859695e-03, 1.7891007e-03, 4.5170286e-03, 6.4557430e-04,\n",
              "        9.8556215e-01], dtype=float32),\n",
              " array([0.9404535 , 0.01354045, 0.01582783, 0.0198644 , 0.01031401],\n",
              "       dtype=float32),\n",
              " array([0.93790406, 0.01341117, 0.01647348, 0.02250241, 0.00970911],\n",
              "       dtype=float32),\n",
              " array([7.5518629e-03, 1.3013330e-03, 4.5454325e-03, 6.6997355e-04,\n",
              "        9.8593110e-01], dtype=float32),\n",
              " array([5.9806583e-03, 1.1573930e-03, 3.8812186e-03, 6.6201400e-04,\n",
              "        9.8831850e-01], dtype=float32),\n",
              " array([8.8465195e-03, 1.8452619e-03, 4.7291415e-03, 7.1425718e-04,\n",
              "        9.8386472e-01], dtype=float32),\n",
              " array([0.79244184, 0.0121141 , 0.02496329, 0.01070674, 0.15977414],\n",
              "       dtype=float32),\n",
              " array([0.92495155, 0.01430458, 0.02082533, 0.02563827, 0.01428012],\n",
              "       dtype=float32),\n",
              " array([0.9214668 , 0.01496392, 0.02309106, 0.0293777 , 0.01110051],\n",
              "       dtype=float32),\n",
              " array([0.13127513, 0.06089665, 0.6162686 , 0.07832411, 0.11323547],\n",
              "       dtype=float32),\n",
              " array([0.01851339, 0.01240463, 0.02167869, 0.00177045, 0.94563293],\n",
              "       dtype=float32),\n",
              " array([0.03497466, 0.00898123, 0.04845036, 0.0049221 , 0.9026716 ],\n",
              "       dtype=float32),\n",
              " array([0.25612554, 0.06857054, 0.4304449 , 0.08019373, 0.16466537],\n",
              "       dtype=float32),\n",
              " array([0.04291357, 0.0143218 , 0.11667107, 0.00909444, 0.8169992 ],\n",
              "       dtype=float32),\n",
              " array([3.6394494e-03, 1.0387421e-03, 4.2537889e-03, 5.9673644e-04,\n",
              "        9.9047124e-01], dtype=float32),\n",
              " array([7.4342075e-03, 2.6424520e-03, 6.7896019e-03, 7.5219182e-04,\n",
              "        9.8238152e-01], dtype=float32),\n",
              " array([0.5807234 , 0.05898604, 0.22836392, 0.09086747, 0.04105898],\n",
              "       dtype=float32),\n",
              " array([0.56956637, 0.06099213, 0.23162639, 0.10360399, 0.03421118],\n",
              "       dtype=float32),\n",
              " array([6.2795319e-03, 1.5215268e-03, 7.4829352e-03, 8.2475838e-04,\n",
              "        9.8389149e-01], dtype=float32),\n",
              " array([3.9926916e-03, 1.0866662e-03, 4.4805305e-03, 6.1232917e-04,\n",
              "        9.8982781e-01], dtype=float32),\n",
              " array([7.7869599e-03, 2.7318359e-03, 7.3104543e-03, 8.2301808e-04,\n",
              "        9.8134774e-01], dtype=float32),\n",
              " array([0.37751463, 0.03370146, 0.12689708, 0.02659001, 0.43529668],\n",
              "       dtype=float32),\n",
              " array([0.38649184, 0.08973201, 0.33126056, 0.14033444, 0.05218112],\n",
              "       dtype=float32),\n",
              " array([0.26084995, 0.03513921, 0.21656951, 0.0328582 , 0.454583  ],\n",
              "       dtype=float32),\n",
              " array([0.08022717, 0.04792308, 0.72508466, 0.05983306, 0.0869321 ],\n",
              "       dtype=float32),\n",
              " array([0.02442886, 0.01946681, 0.0295329 , 0.00231006, 0.92426133],\n",
              "       dtype=float32),\n",
              " array([0.01402411, 0.00369736, 0.01660564, 0.00168937, 0.96398365],\n",
              "       dtype=float32),\n",
              " array([0.11441975, 0.06003397, 0.60461736, 0.05759912, 0.16332985],\n",
              "       dtype=float32),\n",
              " array([0.0142356 , 0.00424432, 0.02364567, 0.00212195, 0.9557525 ],\n",
              "       dtype=float32),\n",
              " array([5.6487527e-03, 1.1143401e-03, 4.0179365e-03, 6.1885419e-04,\n",
              "        9.8859990e-01], dtype=float32),\n",
              " array([1.0471673e-02, 2.5283308e-03, 5.4880586e-03, 7.3038897e-04,\n",
              "        9.8078167e-01], dtype=float32),\n",
              " array([0.05610975, 0.0037301 , 0.01179769, 0.00194924, 0.9264133 ],\n",
              "       dtype=float32),\n",
              " array([0.3964676 , 0.01174968, 0.02990793, 0.00918781, 0.552687  ],\n",
              "       dtype=float32),\n",
              " array([0.90562123, 0.0173434 , 0.02928047, 0.04114782, 0.00660721],\n",
              "       dtype=float32),\n",
              " array([4.8490204e-03, 1.0903800e-03, 3.6954456e-03, 5.7684869e-04,\n",
              "        9.8978812e-01], dtype=float32),\n",
              " array([9.2174439e-03, 2.3059617e-03, 5.2229916e-03, 6.9774268e-04,\n",
              "        9.8255569e-01], dtype=float32),\n",
              " array([0.9389898 , 0.01304409, 0.01725651, 0.01681645, 0.01389317],\n",
              "       dtype=float32),\n",
              " array([0.9311472 , 0.01354998, 0.01924893, 0.01768466, 0.01836939],\n",
              "       dtype=float32),\n",
              " array([6.4894338e-03, 1.2617119e-03, 4.5957090e-03, 6.4024318e-04,\n",
              "        9.8701310e-01], dtype=float32),\n",
              " array([5.1921755e-03, 1.0812685e-03, 4.1950168e-03, 6.7702658e-04,\n",
              "        9.8885453e-01], dtype=float32),\n",
              " array([0.0169018 , 0.0038628 , 0.00765447, 0.00103034, 0.9705505 ],\n",
              "       dtype=float32),\n",
              " array([0.90755373, 0.01907513, 0.03244451, 0.02961941, 0.01130728],\n",
              "       dtype=float32),\n",
              " array([0.8899281 , 0.02066584, 0.03849216, 0.03290588, 0.01800805],\n",
              "       dtype=float32),\n",
              " array([0.01463949, 0.00201163, 0.00944872, 0.00117041, 0.97272986],\n",
              "       dtype=float32),\n",
              " array([6.3335649e-03, 1.1855484e-03, 4.9175927e-03, 7.4877858e-04,\n",
              "        9.8681450e-01], dtype=float32),\n",
              " array([0.05906516, 0.01249607, 0.01838927, 0.00259843, 0.907451  ],\n",
              "       dtype=float32),\n",
              " array([0.8381436 , 0.02598118, 0.06507657, 0.03524721, 0.03555137],\n",
              "       dtype=float32),\n",
              " array([0.19809557, 0.01051679, 0.03975395, 0.00853583, 0.74309784],\n",
              "       dtype=float32),\n",
              " array([0.7734401 , 0.0407034 , 0.09186557, 0.07570987, 0.01828102],\n",
              "       dtype=float32),\n",
              " array([4.3257880e-03, 1.0556238e-03, 4.0425621e-03, 6.3257600e-04,\n",
              "        9.8994344e-01], dtype=float32),\n",
              " array([5.3915479e-03, 1.4909948e-03, 4.4753631e-03, 6.2395661e-04,\n",
              "        9.8801792e-01], dtype=float32),\n",
              " array([0.878246  , 0.02357537, 0.04797856, 0.03711085, 0.01308932],\n",
              "       dtype=float32),\n",
              " array([0.8455071 , 0.02848911, 0.06250765, 0.04880301, 0.01469321],\n",
              "       dtype=float32),\n",
              " array([6.1096423e-03, 1.1913083e-03, 5.0307568e-03, 6.8726850e-04,\n",
              "        9.8698109e-01], dtype=float32),\n",
              " array([4.4464516e-03, 1.0545236e-03, 3.8632951e-03, 5.9020228e-04,\n",
              "        9.9004537e-01], dtype=float32),\n",
              " array([6.0829772e-03, 1.7493530e-03, 4.4189421e-03, 6.0941308e-04,\n",
              "        9.8713917e-01], dtype=float32),\n",
              " array([0.90947896, 0.0186337 , 0.03130778, 0.03171673, 0.00886288],\n",
              "       dtype=float32),\n",
              " array([7.8397002e-03, 1.3934885e-03, 4.9232002e-03, 7.3767058e-04,\n",
              "        9.8510605e-01], dtype=float32),\n",
              " array([6.0134274e-03, 1.2260630e-03, 4.9494854e-03, 6.7021442e-04,\n",
              "        9.8714072e-01], dtype=float32),\n",
              " array([0.07284348, 0.04958069, 0.7209233 , 0.07123037, 0.08542212],\n",
              "       dtype=float32),\n",
              " array([5.2076131e-03, 2.0613566e-03, 6.5046391e-03, 6.9422950e-04,\n",
              "        9.8553210e-01], dtype=float32),\n",
              " array([0.11365104, 0.04621363, 0.60185724, 0.0521336 , 0.18614462],\n",
              "       dtype=float32),\n",
              " array([0.08816321, 0.05204223, 0.7126418 , 0.08036193, 0.06679082],\n",
              "       dtype=float32),\n",
              " array([0.01311028, 0.00387298, 0.02556976, 0.00215743, 0.9552895 ],\n",
              "       dtype=float32),\n",
              " array([0.44019276, 0.08639418, 0.2931046 , 0.13375415, 0.04655429],\n",
              "       dtype=float32),\n",
              " array([0.04145017, 0.0135363 , 0.01722121, 0.00184092, 0.9259515 ],\n",
              "       dtype=float32),\n",
              " array([0.03316025, 0.00373446, 0.0130755 , 0.00176328, 0.94826645],\n",
              "       dtype=float32),\n",
              " array([1.2959350e-02, 2.0967335e-03, 7.1041556e-03, 9.6507848e-04,\n",
              "        9.7687465e-01], dtype=float32),\n",
              " array([0.5003752 , 0.03005259, 0.15802318, 0.02974627, 0.28180274],\n",
              "       dtype=float32),\n",
              " array([0.9005068 , 0.0183971 , 0.03409609, 0.03184422, 0.01515583],\n",
              "       dtype=float32),\n",
              " array([5.4587414e-03, 1.4583066e-03, 4.3860907e-03, 6.0363178e-04,\n",
              "        9.8809332e-01], dtype=float32),\n",
              " array([0.9244015 , 0.0147093 , 0.02617089, 0.0242654 , 0.01045283],\n",
              "       dtype=float32),\n",
              " array([0.9190879 , 0.01495329, 0.02791742, 0.02781749, 0.01022389],\n",
              "       dtype=float32),\n",
              " array([5.7707792e-03, 1.1980404e-03, 4.8880889e-03, 6.5330119e-04,\n",
              "        9.8748988e-01], dtype=float32),\n",
              " array([5.4943012e-03, 1.1089753e-03, 3.9395462e-03, 5.9720722e-04,\n",
              "        9.8886019e-01], dtype=float32),\n",
              " array([6.7971237e-03, 1.5698103e-03, 4.1684532e-03, 5.9057388e-04,\n",
              "        9.8687416e-01], dtype=float32),\n",
              " array([0.9431849 , 0.01182878, 0.01601212, 0.01955026, 0.00942404],\n",
              "       dtype=float32),\n",
              " array([0.82465625, 0.01210885, 0.02166107, 0.0148686 , 0.12670521],\n",
              "       dtype=float32),\n",
              " array([7.0290002e-03, 1.2329795e-03, 4.4758818e-03, 6.3791405e-04,\n",
              "        9.8662442e-01], dtype=float32),\n",
              " array([6.6613755e-03, 1.2712487e-03, 4.4413912e-03, 6.5679580e-04,\n",
              "        9.8696923e-01], dtype=float32),\n",
              " array([0.03441018, 0.00764829, 0.00964233, 0.00136203, 0.9469372 ],\n",
              "       dtype=float32),\n",
              " array([0.9421859 , 0.01191534, 0.01564842, 0.01904282, 0.01120757],\n",
              "       dtype=float32),\n",
              " array([8.9187901e-03, 1.4441151e-03, 4.5661875e-03, 7.0609333e-04,\n",
              "        9.8436505e-01], dtype=float32),\n",
              " array([0.91695917, 0.01328079, 0.02405177, 0.02477171, 0.02093661],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT 확률값 저장\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "results = trainer.predict(test_dataset)\n",
        "\n",
        "results\n",
        "\n",
        "scores = [softmax(prediction) for prediction in results.predictions]\n",
        "#predicted_labels = [np.argmax(x) for x in scores]\n",
        "\n",
        "#results = trainer.predict(test_dataset)\n",
        "#results\n",
        "pd.DataFrame(scores).to_csv('BERT_predtb.csv', index=False)\n",
        "BERT_pred_tb = pd.read_csv('/content/BERT_predtb.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Kl-Qbpsw1LxU",
        "outputId": "2508c0b8-0603-4f14-ab39-986e0d924744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 4000\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BERT_pred_tb = pd.read_csv('/content/BERT_predtb.csv')"
      ],
      "metadata": {
        "id": "vVPK0KePLuxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XLM 확률값 저장\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "results2 = trainer.predict(test_dataset)\n",
        "\n",
        "results2\n",
        "\n",
        "scores2 = [softmax(prediction) for prediction in results2.predictions]\n",
        "#predicted_labels = [np.argmax(x) for x in scores]\n",
        "\n",
        "#results = trainer.predict(test_dataset)\n",
        "#results\n",
        "pd.DataFrame(scores2).to_csv('XLM_KR3_predtb.csv', index=False)\n",
        "XLM_pred_tb = pd.read_csv('/content/XLM_KR3_predtb.csv')"
      ],
      "metadata": {
        "id": "Es5oguSZ26zZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "5a85b5cc-d91d-4e0f-ff1e-62517a0f2340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 4005\n",
            "  Batch size = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-021d30a49b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XLM_predtb.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mXLM_pred_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/XLM_KR3_predtb.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/XLM_KR3_predtb.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XLM_pred_tb = pd.read_csv('/content/XLM_predtb.csv')"
      ],
      "metadata": {
        "id": "BM84-Af3LxLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Averaging 앙상블 함수 \n",
        "#평가지표가 roc-auc, logloss 등일 경우 산술평균, 기하평균, 조화평균, 멱평균(power mean) 사용, 그 중 멱평균\n",
        "#p=1일 때 산술평균, p=0일 때 기하평균, p=-1일 때 조화평균\n",
        "def averaging_ensemble(list_ = [], cols_size = 5, p=1):\n",
        "    \"\"\"\n",
        "    list_ : 클래스별 확률테이블 작성\n",
        "    \"\"\"\n",
        "    list_size = len(list_)\n",
        "    if list_size < 2:\n",
        "        print(\"2개 이상 넣기\")\n",
        "        return\n",
        "    \n",
        "    pred_means = []\n",
        "    for s_ in range(cols_size):\n",
        "        \n",
        "        preds = [v.iloc[:, s_].tolist() for v in list_]\n",
        "            \n",
        "        if p == 0:\n",
        "            pred_mean = gmean(preds, axis=0)\n",
        "        else:\n",
        "            pred_mean = (np.sum(np.array(preds)**p, axis=0) / len(list_))**(1/p)\n",
        "        \n",
        "        pred_means.append(pred_mean)\n",
        "        \n",
        "    return pred_means"
      ],
      "metadata": {
        "id": "jC6maqUS261s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_list = [\n",
        "    # BERT\n",
        "    BERT_pred_tb, # \n",
        "\n",
        "    # XLM ROBERTA\n",
        "    XLM_pred_tb, # \n",
        "\n",
        "]\n",
        "\n",
        "p=1\n",
        "pred_means = averaging_ensemble(list_=submission_list, p=p)"
      ],
      "metadata": {
        "id": "CHXYL59K264V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "pred_table = pd.DataFrame()\n",
        "\n",
        "for i, pred in enumerate(tqdm(pred_means)):\n",
        "    pred_table[i] = pred\n",
        "  \n",
        "\n",
        "\n",
        "pred_table\n",
        "\n",
        "predicted_labels = np.argmax(np.array(pred_table),axis = 1)\n",
        "\n",
        "#sample_sub['label'] = np.argmax(np.array(pred_table),axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOaYcj6ghnRb",
        "outputId": "a9e801f0-423e-44bf-a286-824463eca795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 1231.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = pred_table.values.tolist()\n",
        "#list.toArray(scores2)"
      ],
      "metadata": {
        "id": "WyGF7K9DEzak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scores = pred_means\n",
        "\n",
        "\n",
        "def compute_semeval_accuracy(test_labels, predicted_labels, scores, num_classes=4):\n",
        "    count_considered_examples = 0\n",
        "    count_correct_examples = 0\n",
        "    if num_classes == 4:\n",
        "        for i in range(len(test_labels)):\n",
        "            if test_labels[i] == 4:\n",
        "                continue\n",
        "            new_predicted_label = predicted_labels[i]\n",
        "            if new_predicted_label == 4:\n",
        "                new_scores = scores[i].copy()\n",
        "                new_scores[4] = 0\n",
        "                new_predicted_label = np.argmax(new_scores)\n",
        "            if test_labels[i] == new_predicted_label:\n",
        "                count_correct_examples += 1\n",
        "            count_considered_examples += 1\n",
        "        semeval_accuracy = count_correct_examples / count_considered_examples\n",
        "\n",
        "    elif num_classes == 3:\n",
        "        for i in range(len(test_labels)):\n",
        "            if test_labels[i] >= 3:\n",
        "                continue\n",
        "            new_predicted_label = predicted_labels[i]\n",
        "            if new_predicted_label >= 3:\n",
        "                new_scores = scores[i].copy()\n",
        "                new_scores[3] = 0\n",
        "                new_scores[4] = 0\n",
        "                new_predicted_label = np.argmax(new_scores)\n",
        "            if test_labels[i] == new_predicted_label:\n",
        "                count_correct_examples += 1\n",
        "            count_considered_examples += 1\n",
        "        semeval_accuracy = count_correct_examples / count_considered_examples\n",
        "    elif num_classes == 2:\n",
        "        for i in range(len(test_labels)):\n",
        "            if test_labels[i] == 1 or test_labels[i] >= 3:\n",
        "                continue\n",
        "            new_predicted_label = predicted_labels[i]\n",
        "            if new_predicted_label == 1 or new_predicted_label >= 3:\n",
        "                new_scores = scores[i].copy()\n",
        "                new_scores[1] = 0\n",
        "                new_scores[3] = 0\n",
        "                new_scores[4] = 0\n",
        "                new_predicted_label = np.argmax(new_scores)\n",
        "            if test_labels[i] == new_predicted_label:\n",
        "                count_correct_examples += 1\n",
        "            count_considered_examples += 1\n",
        "        semeval_accuracy = count_correct_examples / count_considered_examples\n",
        "    else:\n",
        "        raise ValueError(\"num_classes must be equal to 2, 3, or 4\")\n",
        "    return semeval_accuracy"
      ],
      "metadata": {
        "id": "rc_U2YfGAtLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p, r, f1 = evaluation.compute_semeval_PRF(test_labels, predicted_labels)\n",
        "four_way = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 4)\n",
        "three_way = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 3)\n",
        "two_way = evaluation.compute_semeval_accuracy(test_labels, predicted_labels, scores, 2)\n",
        "print(p)\n",
        "print(r)\n",
        "print(f1)\n",
        "print(four_way)\n",
        "print(three_way)\n",
        "print(two_way)"
      ],
      "metadata": {
        "id": "TTZjQV6V27Ct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88169bcf-e7bc-4b1f-a82a-69b0c8ea4dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.937007874015748\n",
            "0.8126829268292682\n",
            "0.87042842215256\n",
            "0.7824390243902439\n",
            "0.8242548818088387\n",
            "0.8964732650739476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_output = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "df = pd.DataFrame(csv_output)\n",
        "df[0] = df[0].astype(\"int\")\n",
        "if task.endswith(\"B\"):\n",
        "    header = [\"predicted_label\", \"no\", \"yes\"]\n",
        "else:\n",
        "    header = [\"predicted_label\"]\n",
        "    for label in label2id.keys():\n",
        "        header.append(label)\n",
        "df.to_csv(f\"{base_dir}/results/{dataset_type}/BERT-pair/{task}.csv\", index=False, header=header)"
      ],
      "metadata": {
        "id": "HvGN-LBl1OAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if base_dir not in sys.path:\n",
        "    sys.path.insert(0, f'{base_dir}/')\n",
        "import evaluation\n",
        "evaluation.main(task, dataset_type, f\"{base_dir}/data\", f\"{base_dir}/results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "lD1PZUKuthG6",
        "outputId": "709d7806-3adf-4ccf-f298-e2e7c90f785c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-848ca2cc90ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{base_dir}/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{base_dir}/data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{base_dir}/results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/gdrive/MyDrive/Machine_Learning/evaluation.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(task, dataset_type, data_dir, predictions_path)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdataset_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"semeval2014\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         semeval_aspect_precision, semeval_aspect_recall, semeval_aspect_micro_F1 = compute_semeval_PRF(test_labels,\n\u001b[0;32m--> 264\u001b[0;31m                                                                                                        predicted_labels)\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{task} Semeval aspect precision: {semeval_aspect_precision}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{task} Semeval aspect recall: {semeval_aspect_recall}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/gdrive/MyDrive/Machine_Learning/evaluation.py\u001b[0m in \u001b[0;36mcompute_semeval_PRF\u001b[0;34m(test_labels, predicted_labels)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mtest_aspects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                 \u001b[0mpredicted_aspects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_aspects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluation"
      ],
      "metadata": {
        "id": "M3W8dgKMean7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "KR3_pair_test = pd.read_csv('/content/KR3_pair_test.csv')\n",
        "KR3_pair_test"
      ],
      "metadata": {
        "id": "yIdMEoMM1P8U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "d693803d-7a17-4fec-82ad-6bebc4621623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-775c8755f61b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mKR3_pair_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/KR3_pair_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mKR3_pair_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/KR3_pair_test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KR3_pair_test = KR3_pair_test.sort_values(by=['original_sentence'])\n",
        "pd.DataFrame(KR3_pair_test).to_csv('KR3_pair_test.csv', index=False)"
      ],
      "metadata": {
        "id": "lNU5IB7i1QBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5d97d62b-218d-42b4-f51f-d73dd83aba8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                  original_sentence  \\\n",
              "0      0  1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...   \n",
              "1      0  1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...   \n",
              "2      0  1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...   \n",
              "3      0  1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...   \n",
              "4      0  1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...   \n",
              "...   ..                                                ...   \n",
              "4000   2                       후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요   \n",
              "4001   2                       후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요   \n",
              "4002   2                       후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요   \n",
              "4003   2                       후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요   \n",
              "4004   2                       후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요   \n",
              "\n",
              "     auxiliary_sentence  label_id label  \n",
              "0                    가격         2    부정  \n",
              "1                    일화         4    없음  \n",
              "2                    음식         2    부정  \n",
              "3                   분위기         4    없음  \n",
              "4                   서비스         2    부정  \n",
              "...                 ...       ...   ...  \n",
              "4000                 가격         4    없음  \n",
              "4001                 일화         4    없음  \n",
              "4002                 음식         4    없음  \n",
              "4003                분위기         0    긍정  \n",
              "4004                서비스         4    없음  \n",
              "\n",
              "[4005 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3156199-fa16-421f-a612-bc62d40d65f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_sentence</th>\n",
              "      <th>auxiliary_sentence</th>\n",
              "      <th>label_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...</td>\n",
              "      <td>가격</td>\n",
              "      <td>2</td>\n",
              "      <td>부정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...</td>\n",
              "      <td>일화</td>\n",
              "      <td>4</td>\n",
              "      <td>없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...</td>\n",
              "      <td>음식</td>\n",
              "      <td>2</td>\n",
              "      <td>부정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...</td>\n",
              "      <td>분위기</td>\n",
              "      <td>4</td>\n",
              "      <td>없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1. 맛없고 짜고 조미료 범벅. 특히, 떡볶이와 어묵 국물 못 먹을 정도의 짠맛 다...</td>\n",
              "      <td>서비스</td>\n",
              "      <td>2</td>\n",
              "      <td>부정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4000</th>\n",
              "      <td>2</td>\n",
              "      <td>후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요</td>\n",
              "      <td>가격</td>\n",
              "      <td>4</td>\n",
              "      <td>없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4001</th>\n",
              "      <td>2</td>\n",
              "      <td>후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요</td>\n",
              "      <td>일화</td>\n",
              "      <td>4</td>\n",
              "      <td>없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4002</th>\n",
              "      <td>2</td>\n",
              "      <td>후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요</td>\n",
              "      <td>음식</td>\n",
              "      <td>4</td>\n",
              "      <td>없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>2</td>\n",
              "      <td>후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요</td>\n",
              "      <td>분위기</td>\n",
              "      <td>0</td>\n",
              "      <td>긍정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4004</th>\n",
              "      <td>2</td>\n",
              "      <td>후식으로 차 한 잔은 이곳의 분위기를 더욱 더해줘요</td>\n",
              "      <td>서비스</td>\n",
              "      <td>4</td>\n",
              "      <td>없음</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4005 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3156199-fa16-421f-a612-bc62d40d65f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3156199-fa16-421f-a612-bc62d40d65f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3156199-fa16-421f-a612-bc62d40d65f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMjpw6u61QEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43yDy_HX1QHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53mKWMK91QK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWCkf7ub1QMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RxbQlVk81QPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "95-YmhQF1QRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CzAJS0GT1QUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUvMfIym1QXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43bKgO9i1QZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90VCeRw71Qb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a dataset and a task { run: \"auto\", display-mode: \"form\" }\n",
        "base_dir = \"/gdrive/MyDrive/Machine_Learning\" #@param {type:\"string\"}\n",
        "dataset_type = \"semeval2014\" #@param [\"sentihood\", \"semeval2014\"]\n",
        "task = \"single\" #@param [\"single\"]"
      ],
      "metadata": {
        "id": "NhB1i_9JthPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    id2label = {0: \"None\", 1: \"Positive\", 2: \"Negative\"}\n",
        "    label2id = {\"None\": 0, \"Positive\": 1, \"Negative\": 2}\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    id2label = {0: \"긍정\", 1: \"중립\", 2: \"부정\", 3: \"대립\", 4: \"없음\"}\n",
        "    label2id = {\"긍정\": 0, \"중립\" : 1, \"부정\" : 2, \"대립\": 3, \"없음\": 4}\n",
        "\n",
        "if dataset_type == \"sentihood\":\n",
        "    num_classes = 3\n",
        "    locations = [\"location_1_\", \"location_2_\"]\n",
        "    aspects = [\"general\", \"price\", \"safety\", \"transit location\"]\n",
        "elif dataset_type == \"semeval2014\":\n",
        "    num_classes = 5\n",
        "    locations = [\"\"]\n",
        "    aspects = [\"분위기\", \"일화\", \"음식\", \"가격\", \"서비스\"]\n",
        "\n",
        "\n",
        "def get_dataset(path):\n",
        "    original_sentences = []\n",
        "    labels = []\n",
        "    data = pd.read_csv(path, header=0, error_bad_lines= False).values.tolist()\n",
        "    for row in data:\n",
        "        original_sentences.append(row[1])\n",
        "        labels.append(row[3])\n",
        "    return original_sentences, labels\n",
        "\n",
        "\n",
        "train_original_sentences = {}\n",
        "train_labels = {}\n",
        "val_original_sentences = {}\n",
        "val_labels = {}\n",
        "test_original_sentences = {}\n",
        "test_labels = {}\n",
        "\n",
        "for location in locations:\n",
        "    train_original_sentences[location] = {}\n",
        "    train_labels[location] = {}\n",
        "    val_original_sentences[location] = {}\n",
        "    val_labels[location] = {}\n",
        "    test_original_sentences[location] = {}\n",
        "    test_labels[location] = {}\n",
        "    for aspect in aspects:\n",
        "        train_original_sentences[location][aspect], train_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/train.csv\")\n",
        "        if dataset_type == \"sentihood\":\n",
        "            val_original_sentences[location][aspect], val_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/dev.csv\")\n",
        "        elif dataset_type == \"semeval2014\":\n",
        "            val_original_sentences[location][aspect], val_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/test.csv\")\n",
        "            test_original_sentences[location][aspect], test_labels[location][aspect] = get_dataset(f\"{base_dir}/data/{dataset_type}/BERT-single/{location}{aspect}/test.csv\")"
      ],
      "metadata": {
        "id": "Sk-WtIuqqe-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4428d36a-23a7-4826-ee0f-da5b9f00e7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT용\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "train_encodings = {}\n",
        "val_encodings = {}\n",
        "test_encodings = {}\n",
        "for location in locations:\n",
        "    train_encodings[location] = {}\n",
        "    val_encodings[location] = {}\n",
        "    test_encodings[location] = {}\n",
        "    for aspect in aspects:\n",
        "        train_encodings[location][aspect] = tokenizer(train_original_sentences[location][aspect], truncation=True, padding=True)\n",
        "        val_encodings[location][aspect] = tokenizer(val_original_sentences[location][aspect], truncation=True, padding=True)\n",
        "        test_encodings[location][aspect] = tokenizer(test_original_sentences[location][aspect], truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "E8S-z_o4qfBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "211396f217b149d9bb19c67d888090b3",
            "9c8ab1d4744a40d8b236c7f51339386b",
            "6ea5086b34484615ac071d3197b1670b",
            "299581a1e28f476ba9db2724a6708063",
            "f584e6fcb6ca4811ace04689c8d8d170",
            "c2c67033d43948ecb39f2e792ee69e7c",
            "f7474c5fd9a94863aab3d1caed0f1c24",
            "71486a381d9d4975b92bbbf53d567cfc",
            "f424f4c4852042cbb2f614a410172763",
            "f175b89af12d4089abe9f36c7a58ca3b",
            "faed7e1805e44925ab8b38e819c0a6b2",
            "c24446e0af3043d2b6f228bb797dd2a6",
            "12477fe111bd4fb5b91fb04c341cc129",
            "a6b3880a035d44d08119c303232d982a",
            "8e1249de65be4b5bbf2cc389d5ad30c8",
            "dfcdd0ffdf01413aadef00d8409e0f41",
            "601905689cd94203968b67c7d0b03dbe",
            "1b0cbb5c0c5347dfa711582d6a641bab",
            "b4d7eee94ccd49b2b8318c765b71a8a7",
            "69daba0d8110488f8cc131a685d9b5c1",
            "55f064a979994f91a5ee61eebefb55b2",
            "988868bc0aa34c7496cd962b556753cd",
            "15eb78a926844dfb8ecd61523a444e07",
            "024bedb9c0674d9eb9185293ef809b22",
            "68fb25f7ff9e43ffa4d886f98926ee42",
            "48e86378f5d5478fa2ec418f11d7214c",
            "2359ecf2da98418d87b1de02b296b544",
            "11839a87991d448990eb832a5869ec44",
            "6e41c9c2d7b44df9adf30a54cf5675f8",
            "ad4e08831357475b838f4727d64aa1f7",
            "f52ac214fd5c4308a293577c9196c4fd",
            "146fcb4c9baa4edea23d2825ea2ed34b",
            "8e64c96abc4348f886a5d19f3e74da11"
          ]
        },
        "outputId": "0c3450cd-a680-41b5-b715-6ca0e53436a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "211396f217b149d9bb19c67d888090b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c24446e0af3043d2b6f228bb797dd2a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15eb78a926844dfb8ecd61523a444e07"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XLM-RoBERTa용\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "train_encodings = {}\n",
        "val_encodings = {}\n",
        "test_encodings = {}\n",
        "for location in locations:\n",
        "    train_encodings[location] = {}\n",
        "    val_encodings[location] = {}\n",
        "    test_encodings[location] = {}\n",
        "    for aspect in aspects:\n",
        "        train_encodings[location][aspect] = tokenizer(train_original_sentences[location][aspect], truncation=True, padding=True)\n",
        "        val_encodings[location][aspect] = tokenizer(val_original_sentences[location][aspect], truncation=True, padding=True)\n",
        "        test_encodings[location][aspect] = tokenizer(test_original_sentences[location][aspect], truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "RHZRzyNsSDQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class ABSA_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataset = {}\n",
        "val_dataset = {}\n",
        "test_dataset = {}\n",
        "for location in locations:\n",
        "    train_dataset[location] = {}\n",
        "    val_dataset[location] = {}\n",
        "    test_dataset[location] = {}\n",
        "    for aspect in aspects:\n",
        "        train_dataset[location][aspect] = ABSA_Dataset(train_encodings[location][aspect], train_labels[location][aspect])\n",
        "        val_dataset[location][aspect] = ABSA_Dataset(val_encodings[location][aspect], val_labels[location][aspect])\n",
        "        test_dataset[location][aspect] = ABSA_Dataset(test_encodings[location][aspect], test_labels[location][aspect])"
      ],
      "metadata": {
        "id": "OerRjgw7qfFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[location][aspect]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZtnv69yTXyr",
        "outputId": "ef5cbcff-4503-48c0-8ebe-e1e73bf155ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ABSA_Dataset at 0x7f4a75e8e5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT용\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertConfig\n",
        "from transformers import logging\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "logging.set_verbosity_debug()\n",
        "\n",
        "\n",
        "epochs = 2\n",
        "batch_size = 24\n",
        "\n",
        "header = [\"predicted_label\"]\n",
        "for label in label2id.keys():\n",
        "    header.append(label)\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "        'bert-base-multilingual-cased',\n",
        "        architectures = ['BertForSequenceClassification'],\n",
        "        hidden_size = 768,\n",
        "        num_hidden_layers = 12,\n",
        "        num_attention_heads = 12,\n",
        "        hidden_dropout_prob = 0.1,\n",
        "        num_labels = num_classes\n",
        "    )    \n",
        "\n",
        "for location in locations:\n",
        "    for aspect in aspects:\n",
        "        num_steps = len(train_dataset[location][aspect]) * epochs // batch_size\n",
        "        warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "        save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir = f'{base_dir}/models/{dataset_type}/BERT-single/{location}{aspect}/',          \n",
        "            num_train_epochs = epochs,              \n",
        "            per_device_train_batch_size = batch_size,  \n",
        "            per_device_eval_batch_size = batch_size,   \n",
        "            warmup_steps = warmup_steps,   \n",
        "            weight_decay = 0.01,               \n",
        "            logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-single/{location}{aspect}/',            \n",
        "            logging_steps = 10,\n",
        "            evaluation_strategy = 'epoch',\n",
        "            learning_rate = 2e-5,\n",
        "            save_steps = save_steps,\n",
        "            seed=21\n",
        "        )\n",
        "\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', config=config)\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,                         \n",
        "            args=training_args,                  \n",
        "            train_dataset=train_dataset[location][aspect],         \n",
        "            eval_dataset=val_dataset[location][aspect]             \n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        model.save_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-single/{location}{aspect}/last_step\")\n",
        "\n",
        "        results = trainer.predict(test_dataset[location][aspect])\n",
        "\n",
        "        scores = [softmax(prediction) for prediction in results.predictions]\n",
        "        predicted_labels = [np.argmax(x) for x in scores]\n",
        "\n",
        "        csv_output = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "        df = pd.DataFrame(csv_output)\n",
        "        df[0] = df[0].astype(\"int\")\n",
        "        df.to_csv(f\"{base_dir}/results/{dataset_type}/BERT-single/{location}{aspect}.csv\", index=False, header=header)\n",
        "\n",
        "        del training_args\n",
        "        del model\n",
        "        del trainer\n",
        "        del results\n",
        "        del scores\n",
        "        del predicted_labels\n",
        "        del csv_output\n",
        "        del df\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "1c7F7MQOqfI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b5643d3e3430433782d9a5fa535086bc",
            "9fe1a0c2063a44388b6929943eaa2bcc",
            "2cff1c721cd14eb9a254660c94650e82",
            "8a4c9c70fffa4a0ea2ecabf719166a9a",
            "e44aab92633e4410acd4195a0780a9f8",
            "f83aabc7f7604dddada5c8591d47299d",
            "25b875fcf6a944979004802b484a99bc",
            "9b432bcc3e1342e4af14451b198d3ce7",
            "904bec2668f6410b86efe261d895cf48",
            "0d48399019da48f5bdd53bc897d5da17",
            "e1937fdb466c4309841f2913d2e3f38d"
          ]
        },
        "outputId": "17bd57e2-4d94-4150-aa2a-02f8566cae24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5643d3e3430433782d9a5fa535086bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 02:22, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.393400</td>\n",
              "      <td>0.371974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.423200</td>\n",
              "      <td>0.340058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 02:30, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.737300</td>\n",
              "      <td>0.641676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.695600</td>\n",
              "      <td>0.606066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 02:34, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.648600</td>\n",
              "      <td>0.679252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.505100</td>\n",
              "      <td>0.636288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 02:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.229000</td>\n",
              "      <td>0.196250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.150900</td>\n",
              "      <td>0.168086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/cf732291d5a8eace7b973ccd13c95ec07b19e734/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 02:33, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.405400</td>\n",
              "      <td>0.339745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.301800</td>\n",
              "      <td>0.290007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XLM-RoBERTa용\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig, Trainer, TrainingArguments\n",
        "from transformers import logging\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "logging.set_verbosity_debug()\n",
        "\n",
        "epochs = 2\n",
        "batch_size = 24\n",
        "\n",
        "header = [\"predicted_label\"]\n",
        "for label in label2id.keys():\n",
        "    header.append(label)\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "        'xlm-roberta-base',\n",
        "        architectures = ['AutoModelForSequenceClassification'],\n",
        "        hidden_size = 768,\n",
        "        num_hidden_layers = 12,\n",
        "        num_attention_heads = 12,\n",
        "        hidden_dropout_prob = 0.1,\n",
        "        num_labels = num_classes\n",
        "    )    \n",
        "\n",
        "for location in locations:\n",
        "    for aspect in aspects:\n",
        "        num_steps = len(train_dataset[location][aspect]) * epochs // batch_size\n",
        "        warmup_steps = num_steps // 10  # 10% of the training steps\n",
        "        save_steps = num_steps // epochs    # Save a checkpoint at the end of each epoch\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir = f'{base_dir}/models/{dataset_type}/BERT-single/{location}{aspect}/',          \n",
        "            num_train_epochs = epochs,              \n",
        "            per_device_train_batch_size = batch_size,  \n",
        "            per_device_eval_batch_size = batch_size,   \n",
        "            warmup_steps = warmup_steps,   \n",
        "            weight_decay = 0.01,               \n",
        "            logging_dir = f'{base_dir}/logs/{dataset_type}/BERT-single/{location}{aspect}/',            \n",
        "            logging_steps = 10,\n",
        "            evaluation_strategy = 'epoch',\n",
        "            learning_rate = 2e-5,\n",
        "            save_steps = save_steps,\n",
        "            seed=21\n",
        "        )\n",
        "\n",
        "        model = BertForSequenceClassification.from_pretrained('xlm-roberta-base', config=config)\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,                         \n",
        "            args=training_args,                  \n",
        "            train_dataset=train_dataset[location][aspect],         \n",
        "            eval_dataset=val_dataset[location][aspect]             \n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        model.save_pretrained(f\"{base_dir}/models/{dataset_type}/BERT-single/{location}{aspect}/last_step\")\n",
        "\n",
        "        results = trainer.predict(test_dataset[location][aspect])\n",
        "\n",
        "        scores = [softmax(prediction) for prediction in results.predictions]\n",
        "        predicted_labels = [np.argmax(x) for x in scores]\n",
        "\n",
        "        csv_output = np.insert(scores, 0, predicted_labels, axis=1)\n",
        "        df = pd.DataFrame(csv_output)\n",
        "        df[0] = df[0].astype(\"int\")\n",
        "        df.to_csv(f\"{base_dir}/results/{dataset_type}/BERT-single/{location}{aspect}.csv\", index=False, header=header)\n",
        "\n",
        "        del training_args\n",
        "        del model\n",
        "        del trainer\n",
        "        del results\n",
        "        del scores\n",
        "        del predicted_labels\n",
        "        del csv_output\n",
        "        del df\n",
        "        gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f530a458bce84e30baf3a1d05d89a711",
            "5cf1b84451364edabc85b334196fec34",
            "5989bbfc09e24da9a4c45ec46ecaf5c4",
            "62b5dce8de7e4c3f9be585cd9ce55bf6",
            "605894d90e6f403b8b8b8a510f907bc1",
            "78eb09d5047d40e382a26fd529ee88e3",
            "b5746a98b5d14d9cbe2592f329324a23",
            "443034b8656a4d74ab1d5defe008d02a",
            "b32bde4dce1b4fd09afb86c1ea8fc56e",
            "21c7fc2e2b75495d8524e680fe3af3c0",
            "a4cbaad7625c481a9b28ef49e46ca624",
            "9c7c0d98e3e140c3998f80b2d19030c5",
            "59778dce2ddb48d38466046aebf5ca4b",
            "aad1730e72e94166950598de858504eb",
            "25767eeb91624772b91d59aa049bdd5c",
            "5579b9b73a694c798df54cdd9410ab68",
            "cd5247b467b94c69b0c1b131f8a3a959",
            "62b4551487f9439fa47222b5a2c9040b",
            "e100b2487f7e44e19e17b0812aaf6a0e",
            "d209f8be403a4246833039e664c1780c",
            "2c99c615a3114db5863c66008dfbd4f8",
            "d488761492a24f3ba3fa43e43a2c29d6"
          ]
        },
        "id": "7B0ZczUmS3ov",
        "outputId": "1b758fd0-9547-4f3c-85d8-2996e137feaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f530a458bce84e30baf3a1d05d89a711"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/config.json\n",
            "You are using a model of type xlm-roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"AutoModelForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c7c0d98e3e140c3998f80b2d19030c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.10.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'classifier.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 03:46, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.540600</td>\n",
              "      <td>0.588181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.561200</td>\n",
              "      <td>0.536893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/분위기/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.10.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'classifier.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 03:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.951500</td>\n",
              "      <td>0.934600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.825500</td>\n",
              "      <td>0.752609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/일화/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.10.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'classifier.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 03:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.946400</td>\n",
              "      <td>0.937403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.687600</td>\n",
              "      <td>0.838047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/음식/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.10.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'classifier.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 03:34, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.470400</td>\n",
              "      <td>0.421218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.257600</td>\n",
              "      <td>0.312146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/가격/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/f6d161e8f5f6f2ed433fb4023d6cb34146506b3f/pytorch_model.bin\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.10.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'classifier.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'classifier.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3044\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 24\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 03:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.604300</td>\n",
              "      <td>0.583020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.424300</td>\n",
              "      <td>0.422755</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-126\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-126/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-126/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "Saving model checkpoint to /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-252\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-252/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/checkpoint-252/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/last_step/config.json\n",
            "Model weights saved in /gdrive/MyDrive/Machine_Learning/models/semeval2014/BERT-single/서비스/last_step/pytorch_model.bin\n",
            "***** Running Prediction *****\n",
            "  Num examples = 800\n",
            "  Batch size = 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if base_dir not in sys.path:\n",
        "    sys.path.insert(0, f'{base_dir}/')\n",
        "import evaluation\n",
        "\n",
        "\n",
        "evaluation.main(task, dataset_type, f\"{base_dir}/data\", f\"{base_dir}/results\")"
      ],
      "metadata": {
        "id": "GzO6S8LiqfMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5227b52-80ff-42dd-e8c2-4d2db1a4a2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "single Semeval aspect precision: 0.9100719424460432\n",
            "single Semeval aspect recall: 0.49365853658536585\n",
            "single Semeval aspect micro F1: 0.6401012017710309\n",
            "single Semeval 4-classes accuracy: 0.6292682926829268\n",
            "single Semeval 3-classes accuracy: 0.6628982528263104\n",
            "single Semeval 2-classes accuracy: 0.7519908987485779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dCoFlVqNqfT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fo2HqFCQqfZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-eYChQkqfh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvw6IoMZqfmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5gEiegGgqfsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAVuh3nKqfzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaozYrWcqf-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZZjOJmqqgFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IVXHuLo-qgLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m1AZbsn2qgQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lLQJcOnqgVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGfqGKUoqgav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUPMcn_hi6bd",
        "outputId": "789fdcd0-850a-4774-9612-ec5c9123e5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HSLCY/ABSA-BERT-pair.git\n",
        "%cd ABSA-BERT-pair/\n",
        "%cd generate/\n",
        "!bash make.sh sentihood\n",
        "!bash make.sh semeval"
      ],
      "metadata": {
        "id": "5oVZV_oXjpJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pi-EuYz6XyDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWWXXiGMXyKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}